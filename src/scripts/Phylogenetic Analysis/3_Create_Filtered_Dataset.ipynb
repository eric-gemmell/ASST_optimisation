{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c4ea7b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Cluster and remove highly similar sequences</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f32b125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def remove_gaps(seq_record):\n",
    "    seq = seq_record.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    return SeqRecord(seq_without_gaps, id=seq_record.id, description=seq_record.description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1da76",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50920cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Filtered Dataset for phylogenetic analysis '../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_70_ID_initial_MSA.fa'\n"
     ]
    }
   ],
   "source": [
    "cluster_min_size = 5\n",
    "skip_cluster = False\n",
    "overwrite_cluster = False\n",
    "ID_cutoff = 0.7\n",
    "input_MSA_filename = \"../../../data/ASST_processed_sequences/initial_MSA/clustalo_MSA.fa\"\n",
    "dataset_name = \"clustalo\"\n",
    "\n",
    "work_dir = \"../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/\"\n",
    "cluster_script_filename = \"../../external_scripts/ClusterMSA.py\"\n",
    "\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "if not skip_cluster:\n",
    "    cluster_str = f\"{cluster_min_size}_per_cluster\"\n",
    "else:\n",
    "    cluster_str = \"no_cluster\"\n",
    "cluster_dir = os.path.join(work_dir,dataset_name +f\"_{cluster_str}_clusters\")\n",
    "output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_initial_MSA.fa\")\n",
    "cdhit_input_filename = os.path.join(cluster_dir,\"clustered_sequences.fa\")\n",
    "cdhit_output_filename = os.path.join(cluster_dir,\"cdhit_output.fa\")\n",
    "tree_data_output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_tree_data.tsv\")\n",
    "if not os.path.exists(cluster_dir):\n",
    "    os.makedirs(cluster_dir)\n",
    "\n",
    "\n",
    "print(f\"Creating Filtered Dataset for phylogenetic analysis '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638e53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_sequences = [seqrec for seqrec in SeqIO.parse(input_MSA_filename,\"fasta\")]\n",
    "for seq in focused_sequences:\n",
    "    seq_id = seq.id.split(\".\")[0]\n",
    "    if(seq_id != seq.id):\n",
    "        raise Exception(\"Names are in the wrong format... check MSA, might need to be rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9520c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sequences, and filtering out sequences with fewer than 5 sequences\n",
      "\n",
      "python ../../external_scripts/ClusterMSA.py clst -i ../../../data/ASST_processed_sequences/initial_MSA/clustalo_MSA.fa -o ../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters --gap_cutoff 1.0 --min_samples 5\n",
      "Initiating clustering.\n",
      "Clustering sequences in ../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters\n",
      "clst\n",
      "0 seqs removed for containing more than 100% gaps, 8933 remaining\n",
      "eps\tn_clusters\tn_not_clustered\n",
      "3.00\t22\t1612\n",
      "3.50\t20\t1580\n",
      "4.00\t21\t1534\n",
      "4.50\t18\t1535\n",
      "5.00\t18\t1459\n",
      "5.50\t22\t1478\n",
      "6.00\t23\t1480\n",
      "6.50\t22\t1483\n",
      "7.00\t24\t1410\n",
      "7.50\t25\t1415\n",
      "8.00\t28\t1370\n",
      "8.50\t22\t1382\n",
      "9.00\t29\t1355\n",
      "9.50\t25\t1400\n",
      "10.00\t27\t1353\n",
      "10.50\t26\t1370\n",
      "11.00\t36\t1304\n",
      "11.50\t30\t1290\n",
      "12.00\t30\t1320\n",
      "12.50\t26\t1300\n",
      "13.00\t33\t1279\n",
      "13.50\t37\t1215\n",
      "14.00\t34\t1273\n",
      "14.50\t34\t1212\n",
      "15.00\t31\t1218\n",
      "15.50\t37\t1189\n",
      "16.00\t39\t1149\n",
      "16.50\t44\t1147\n",
      "17.00\t34\t1171\n",
      "17.50\t38\t1133\n",
      "18.00\t41\t1100\n",
      "18.50\t42\t1035\n",
      "19.00\t42\t1038\n",
      "19.50\t37\t991\n",
      "20.00\t43\t963\n",
      "Selected eps=16.50\n",
      "8933 total seqs\n",
      "175 clusters, 3534 of 8933 not clustered (0.40)\n",
      "avg identity to query of unclustered: 0.87\n",
      "avg identity to query of clustered: 0.87\n",
      "writing 10 size-10 uniformly sampled clusters\n",
      "writing 10 size-100 uniformly sampled clusters\n",
      "wrote clustering data to ../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters/clst_clustering_assignments.tsv\n",
      "wrote cluster metadata to ../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters/clst_cluster_metadata.tsv\n",
      "Saved this output to clst.log\n",
      "\n",
      "Filtering out sequences without large clusters.\n",
      "Out of 8934 sequences, 5574 remain.\n"
     ]
    }
   ],
   "source": [
    "clustered_sequences = []\n",
    "\n",
    "print(f\"Clustering sequences, and filtering out sequences with fewer than {cluster_min_size} sequences\\n\")\n",
    "cluster_script = f\"python {cluster_script_filename} clst -i {input_MSA_filename} -o {cluster_dir} --gap_cutoff 1.0 --min_samples {cluster_min_size}\"\n",
    "print(cluster_script)\n",
    "if(not skip_cluster):\n",
    "    if any(filename.endswith(\".a3m\") for filename in os.listdir(cluster_dir)):\n",
    "        print(f\"Previous instance of cluster detected in {cluster_dir}\\n\")\n",
    "        if overwrite_cluster:\n",
    "            print(f\"Overwriting all files in {cluster_dir}\")\n",
    "            !rm -rf {cluster_dir}\n",
    "            os.makedirs(cluster_dir)\n",
    "            !$cluster_script\n",
    "        else:\n",
    "            print(\"Preserving previously created files, skipping clustering step\")\n",
    "    else:\n",
    "        print(\"Initiating clustering.\")\n",
    "        print(f\"Clustering sequences in {cluster_dir}\")\n",
    "        !$cluster_script\n",
    "\n",
    "    import re\n",
    "    pattern = re.compile(r\"clst_\\d{3}\\.a3m\")\n",
    "    for filename in os.listdir(cluster_dir):\n",
    "        if pattern.match(filename):\n",
    "            file_path = os.path.join(cluster_dir, filename)\n",
    "            seqs = [seqrec for seqrec in SeqIO.parse(file_path,\"fasta\")]\n",
    "            if(len(seqs)>cluster_min_size):\n",
    "                clustered_sequences += seqs\n",
    "else:\n",
    "    print(\"Skipping clustering step as requested, if you do not want this, please set skip_cluster to False!\")\n",
    "    clustered_sequences = copy.deepcopy(focused_sequences)\n",
    "    \n",
    "print(f\"\\nFiltering out sequences without large clusters.\\nOut of {len(focused_sequences)} sequences, {len(clustered_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(clustered_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b93bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out sequences with >70.0% identity.\n",
      "\n",
      "/usr/bin/sh: 1: cd-hit: not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters/cdhit_output.fa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltering out sequences with >\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mID_cutoff\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% identity.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd-hit -i $cdhit_input_filename -o $cdhit_output_filename -c $ID_cutoff -n 5 -d 0 -T 8 -M 16000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m cdhit_accessions \u001b[38;5;241m=\u001b[39m [seqrec\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m seqrec \u001b[38;5;129;01min\u001b[39;00m \u001b[43mSeqIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcdhit_output_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     12\u001b[0m low_similarity_sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m accession \u001b[38;5;129;01min\u001b[39;00m cdhit_accessions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/Bio/SeqIO/__init__.py:605\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(handle, format, alphabet)\u001b[0m\n\u001b[1;32m    603\u001b[0m iterator_generator \u001b[38;5;241m=\u001b[39m _FormatToIterator\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterator_generator:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39m_FormatToIterator:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Use Bio.AlignIO to read in the alignments\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (r \u001b[38;5;28;01mfor\u001b[39;00m alignment \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39mparse(handle, \u001b[38;5;28mformat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m alignment)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/Bio/SeqIO/FastaIO.py:223\u001b[0m, in \u001b[0;36mFastaIterator.__init__\u001b[0;34m(self, source, alphabet, title2ids)\u001b[0m\n\u001b[1;32m    204\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe title2ids argument is deprecated. Instead, please use a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator function to modify records returned by the parser. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         BiopythonDeprecationWarning,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle2ids \u001b[38;5;241m=\u001b[39m title2ids\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/Bio/SeqIO/Interfaces.py:45\u001b[0m, in \u001b[0;36mSequenceIterator.__init__\u001b[0;34m(self, source, alphabet, mode, fmt)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe alphabet argument is no longer supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_close_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# not a path, assume we received a stream\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../data/ASST_processed_sequences/clustalo_5_per_cluster_17_01_2024/clustalo_5_per_cluster_clusters/cdhit_output.fa'"
     ]
    }
   ],
   "source": [
    "ungapped_sequences = []\n",
    "for seq in focused_sequences:\n",
    "    ungapped_sequences.append(remove_gaps(seq))\n",
    "\n",
    "SeqIO.write(ungapped_sequences, cdhit_input_filename, \"fasta\")\n",
    "\n",
    "print(f\"Filtering out sequences with >{ID_cutoff*100}% identity.\\n\")\n",
    "!cd-hit -i $cdhit_input_filename -o $cdhit_output_filename -c $ID_cutoff -n 5 -d 0 -T 8 -M 16000\n",
    "\n",
    "cdhit_accessions = [seqrec.id for seqrec in SeqIO.parse(cdhit_output_filename,\"fasta\")]\n",
    "\n",
    "low_similarity_sequences = []\n",
    "for accession in cdhit_accessions:\n",
    "    for seq2 in focused_sequences:\n",
    "        if(seq2.id == accession):\n",
    "            low_similarity_sequences.append(seq2)\n",
    "            break\n",
    "\n",
    "if(len(low_similarity_sequences) != len(cdhit_accessions)):\n",
    "    print(len(low_similarity_sequences), len(focused_sequences))\n",
    "    raise Exception(\"Something has gone wrong, the filtered by id sequences don't map to the same sequences as clustered sequences.\\n Have you run all previous code or overwritten files?\")\n",
    "    \n",
    "print(f\"\\nFiltered out sequences with >{ID_cutoff*100}% identity.\")\n",
    "print(f\"Out of {len(focused_sequences)} sequences, {len(low_similarity_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(low_similarity_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqIO.write(focused_sequences, output_filename, \"fasta\")\n",
    "print(f\"\\nSequences saved in {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e599",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Tree data creation</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b53b09",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f848c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tree_data_filename = \"../processed_sequences/initial_dataset/tree_data.json\"\n",
    "use_alternate_sequences = True\n",
    "alternate_sequences_filename = \"../processed_sequences/clustal_hmm_5_per_cluster_18022023/seqs11.txt\"\n",
    "\n",
    "\n",
    "\n",
    "if(use_alternate_sequences):\n",
    "    tree_data_output_filename = os.path.join(os.path.dirname(alternate_sequences_filename),\"tree_data.tsv\")\n",
    "    focused_sequences = [seqrec for seqrec in SeqIO.parse(alternate_sequences_filename,\"fasta\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_accessions = [seq.id for seq in focused_sequences]\n",
    "sequence_accessions.sort()\n",
    "with open(total_tree_data_filename) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c66033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = list(data[sequence_accessions[0]].keys())\n",
    "tree_data = {}\n",
    "tree_data[\"accessions\"] = sequence_accessions\n",
    "for header in headers:\n",
    "    tree_data[header] = []\n",
    "    if(header == \"related_seq\"):\n",
    "        related_sequences = {}\n",
    "        for accession in sequence_accessions:\n",
    "            for related_seq in data[accession][header]:\n",
    "                if(related_seq[1] not in related_sequences):\n",
    "                    related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "                else:\n",
    "                    if(related_sequences[related_seq[1]][1]>related_seq[0]):\n",
    "                        related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "        tree_data[header] = [\"_\"]*len(sequence_accessions)\n",
    "        for related_seq in list(related_sequences.keys()):\n",
    "                index = sequence_accessions.index(related_sequences[related_seq][0])\n",
    "                tree_data[header][index] = related_seq\n",
    "    else:\n",
    "        for accession in sequence_accessions:\n",
    "            tree_data[header].append(data[accession][header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tree_data_output_filename, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    \n",
    "    # Write header row\n",
    "    writer.writerow(tree_data.keys())\n",
    "    \n",
    "    # Write values rows\n",
    "    rows = zip(*tree_data.values())\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31c451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0456c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
