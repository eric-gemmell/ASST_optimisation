{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c4ea7b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Cluster and remove highly similar sequences</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f32b125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def remove_gaps(seq_record):\n",
    "    seq = seq_record.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    return SeqRecord(seq_without_gaps, id=seq_record.id, description=seq_record.description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1da76",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50920cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Filtered Dataset for phylogenetic analysis '../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_90_ID_initial_MSA.fa'\n"
     ]
    }
   ],
   "source": [
    "cluster_min_size = 5\n",
    "skip_cluster = False\n",
    "overwrite_cluster = False\n",
    "ID_cutoff = 0.9\n",
    "input_MSA_filename = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_MSA.fa\"\n",
    "dataset_name = \"clustalo\"\n",
    "\n",
    "work_dir = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/\"\n",
    "cluster_script_filename = \"../../external_scripts/ClusterMSA.py\"\n",
    "\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "if not skip_cluster:\n",
    "    cluster_str = f\"{cluster_min_size}_per_cluster\"\n",
    "else:\n",
    "    cluster_str = \"no_cluster\"\n",
    "cluster_dir = os.path.join(work_dir,dataset_name +f\"_{cluster_str}_clusters\")\n",
    "output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_initial_MSA.fa\")\n",
    "cdhit_input_filename = os.path.join(cluster_dir,\"clustered_sequences.fa\")\n",
    "cdhit_output_filename = os.path.join(cluster_dir,\"cdhit_output.fa\")\n",
    "tree_data_output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_tree_data.tsv\")\n",
    "if not os.path.exists(cluster_dir):\n",
    "    os.makedirs(cluster_dir)\n",
    "\n",
    "\n",
    "print(f\"Creating Filtered Dataset for phylogenetic analysis '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638e53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_sequences = [seqrec for seqrec in SeqIO.parse(input_MSA_filename,\"fasta\")]\n",
    "for seq in focused_sequences:\n",
    "    seq_id = seq.id.split(\".\")[0]\n",
    "    if(seq_id != seq.id):\n",
    "        raise Exception(\"Names are in the wrong format... check MSA, might need to be rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9520c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sequences, and filtering out sequences with fewer than 5 sequences\n",
      "\n",
      "python ../../external_scripts/ClusterMSA.py clst -i ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_MSA.fa -o ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_clusters --gap_cutoff 1.0 --min_samples 5\n",
      "Previous instance of cluster detected in ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_clusters\n",
      "\n",
      "Preserving previously created files, skipping clustering step\n",
      "\n",
      "Filtering out sequences without large clusters.\n",
      "Out of 6248 sequences, 4681 remain.\n"
     ]
    }
   ],
   "source": [
    "clustered_sequences = []\n",
    "\n",
    "print(f\"Clustering sequences, and filtering out sequences with fewer than {cluster_min_size} sequences\\n\")\n",
    "cluster_script = f\"python {cluster_script_filename} clst -i {input_MSA_filename} -o {cluster_dir} --gap_cutoff 1.0 --min_samples {cluster_min_size}\"\n",
    "print(cluster_script)\n",
    "if(not skip_cluster):\n",
    "    if any(filename.endswith(\".a3m\") for filename in os.listdir(cluster_dir)):\n",
    "        print(f\"Previous instance of cluster detected in {cluster_dir}\\n\")\n",
    "        if overwrite_cluster:\n",
    "            print(f\"Overwriting all files in {cluster_dir}\")\n",
    "            !rm -rf {cluster_dir}\n",
    "            os.makedirs(cluster_dir)\n",
    "            !$cluster_script\n",
    "        else:\n",
    "            print(\"Preserving previously created files, skipping clustering step\")\n",
    "    else:\n",
    "        print(\"Initiating clustering.\")\n",
    "        print(f\"Clustering sequences in {cluster_dir}\")\n",
    "        !$cluster_script\n",
    "\n",
    "    import re\n",
    "    pattern = re.compile(r\"clst_\\d{3}\\.a3m\")\n",
    "    for filename in os.listdir(cluster_dir):\n",
    "        if pattern.match(filename):\n",
    "            file_path = os.path.join(cluster_dir, filename)\n",
    "            seqs = [seqrec for seqrec in SeqIO.parse(file_path,\"fasta\")]\n",
    "            if(len(seqs)>cluster_min_size):\n",
    "                clustered_sequences += seqs\n",
    "else:\n",
    "    print(\"Skipping clustering step as requested, if you do not want this, please set skip_cluster to False!\")\n",
    "    clustered_sequences = copy.deepcopy(focused_sequences)\n",
    "    \n",
    "print(f\"\\nFiltering out sequences without large clusters.\\nOut of {len(focused_sequences)} sequences, {len(clustered_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(clustered_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b93bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out sequences with >90.0% identity.\n",
      "\n",
      "================================================================\n",
      "Program: CD-HIT, V4.8.1 (+OpenMP), Aug 20 2021, 08:39:56\n",
      "Command: cd-hit -i\n",
      "         ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_clusters/clustered_sequences.fa\n",
      "         -o\n",
      "         ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_clusters/cdhit_output.fa\n",
      "         -c 0.9 -n 5 -d 0 -T 8 -M 16000\n",
      "\n",
      "Started: Fri Feb 23 09:17:53 2024\n",
      "================================================================\n",
      "                            Output                              \n",
      "----------------------------------------------------------------\n",
      "Warning: total number of CPUs in the system is 6\n",
      "Actual number of CPUs to be used: 6\n",
      "\n",
      "total seq: 4681\n",
      "longest and shortest : 400 and 200\n",
      "Total letters: 1468584\n",
      "Sequences have been sorted\n",
      "\n",
      "Approximated minimal memory consumption:\n",
      "Sequence        : 2M\n",
      "Buffer          : 6 X 10M = 63M\n",
      "Table           : 2 X 65M = 130M\n",
      "Miscellaneous   : 0M\n",
      "Total           : 196M\n",
      "\n",
      "Table limit with the given memory limit:\n",
      "Max number of representatives: 4000000\n",
      "Max number of word counting entries: 1975408229\n",
      "\n",
      "# comparing sequences from          0  to        585\n",
      "---------- new table with        7 representatives\n",
      "# comparing sequences from        585  to       1097\n",
      ".....................---------- new table with       72 representatives\n",
      "# comparing sequences from       1097  to       1545\n",
      "----------    232 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       1313  to       1734\n",
      "----------    215 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       1519  to       1914\n",
      "----------    182 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       1732  to       2100\n",
      "----------    119 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       1981  to       2318\n",
      "----------    133 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2185  to       2497\n",
      "----------    148 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2349  to       2640\n",
      "----------     96 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2544  to       2811\n",
      "----------    125 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2686  to       2935\n",
      "----------    104 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2831  to       3062\n",
      "----------     84 remaining sequences to the next cycle\n",
      "---------- new table with      100 representatives\n",
      "# comparing sequences from       2978  to       3190\n",
      ".................---------- new table with       98 representatives\n",
      "# comparing sequences from       3190  to       3376\n",
      "...................---------- new table with       33 representatives\n",
      "# comparing sequences from       3376  to       3539\n",
      "........---------- new table with       73 representatives\n",
      "# comparing sequences from       3539  to       3681\n",
      "..................---------- new table with       48 representatives\n",
      "# comparing sequences from       3681  to       4681\n",
      ".................---------- new table with      444 representatives\n",
      "\n",
      "     4681  finished       1775  clusters\n",
      "\n",
      "Approximated maximum memory consumption: 197M\n",
      "writing new database\n",
      "writing clustering information\n",
      "program completed !\n",
      "\n",
      "Total CPU time 2.14\n",
      "\n",
      "Filtered out sequences with >90.0% identity.\n",
      "Out of 4681 sequences, 1775 remain.\n"
     ]
    }
   ],
   "source": [
    "ungapped_sequences = []\n",
    "for seq in focused_sequences:\n",
    "    ungapped_sequences.append(remove_gaps(seq))\n",
    "\n",
    "SeqIO.write(ungapped_sequences, cdhit_input_filename, \"fasta\")\n",
    "\n",
    "print(f\"Filtering out sequences with >{ID_cutoff*100}% identity.\\n\")\n",
    "!cd-hit -i $cdhit_input_filename -o $cdhit_output_filename -c $ID_cutoff -n 5 -d 0 -T 8 -M 16000\n",
    "\n",
    "cdhit_accessions = [seqrec.id for seqrec in SeqIO.parse(cdhit_output_filename,\"fasta\")]\n",
    "\n",
    "low_similarity_sequences = []\n",
    "for accession in cdhit_accessions:\n",
    "    for seq2 in focused_sequences:\n",
    "        if(seq2.id == accession):\n",
    "            low_similarity_sequences.append(seq2)\n",
    "            break\n",
    "\n",
    "if(len(low_similarity_sequences) != len(cdhit_accessions)):\n",
    "    print(len(low_similarity_sequences), len(focused_sequences))\n",
    "    raise Exception(\"Something has gone wrong, the filtered by id sequences don't map to the same sequences as clustered sequences.\\n Have you run all previous code or overwritten files?\")\n",
    "    \n",
    "print(f\"\\nFiltered out sequences with >{ID_cutoff*100}% identity.\")\n",
    "print(f\"Out of {len(focused_sequences)} sequences, {len(low_similarity_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(low_similarity_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389bc8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequences saved in ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_90_ID_initial_MSA.fa\n"
     ]
    }
   ],
   "source": [
    "SeqIO.write(focused_sequences, output_filename, \"fasta\")\n",
    "print(f\"\\nSequences saved in {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e599",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Tree data creation</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b53b09",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f848c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tree_data_filename = \"../processed_sequences/initial_dataset/tree_data.json\"\n",
    "use_alternate_sequences = True\n",
    "alternate_sequences_filename = \"../processed_sequences/clustal_hmm_5_per_cluster_18022023/seqs11.txt\"\n",
    "\n",
    "\n",
    "\n",
    "if(use_alternate_sequences):\n",
    "    tree_data_output_filename = os.path.join(os.path.dirname(alternate_sequences_filename),\"tree_data.tsv\")\n",
    "    focused_sequences = [seqrec for seqrec in SeqIO.parse(alternate_sequences_filename,\"fasta\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_accessions = [seq.id for seq in focused_sequences]\n",
    "sequence_accessions.sort()\n",
    "with open(total_tree_data_filename) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c66033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = list(data[sequence_accessions[0]].keys())\n",
    "tree_data = {}\n",
    "tree_data[\"accessions\"] = sequence_accessions\n",
    "for header in headers:\n",
    "    tree_data[header] = []\n",
    "    if(header == \"related_seq\"):\n",
    "        related_sequences = {}\n",
    "        for accession in sequence_accessions:\n",
    "            for related_seq in data[accession][header]:\n",
    "                if(related_seq[1] not in related_sequences):\n",
    "                    related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "                else:\n",
    "                    if(related_sequences[related_seq[1]][1]>related_seq[0]):\n",
    "                        related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "        tree_data[header] = [\"_\"]*len(sequence_accessions)\n",
    "        for related_seq in list(related_sequences.keys()):\n",
    "                index = sequence_accessions.index(related_sequences[related_seq][0])\n",
    "                tree_data[header][index] = related_seq\n",
    "    else:\n",
    "        for accession in sequence_accessions:\n",
    "            tree_data[header].append(data[accession][header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tree_data_output_filename, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    \n",
    "    # Write header row\n",
    "    writer.writerow(tree_data.keys())\n",
    "    \n",
    "    # Write values rows\n",
    "    rows = zip(*tree_data.values())\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31c451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0456c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
