{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b529c8ec",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Create Filtered Dataset </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6da11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import copy\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981193e-1659-465d-8dfa-b9a33582facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where do you want to save all this data?\n",
    "work_dir = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/\"\n",
    "\n",
    "interpro_filename = \"../../../data/ASST_raw_sequences/interpro_all_ASST_domain_sequences_trimmed.txt\"\n",
    "focused_sequences = [seqrec for seqrec in SeqIO.parse(interpro_filename,\"fasta\")]\n",
    "for seq in focused_sequences:\n",
    "    seq_id = seq.id.split(\".\")[0]\n",
    "    seq.id = seq_id\n",
    "    seq.name = seq_id\n",
    "    seq.description = seq_id\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "alignment_input_filename = os.path.join(work_dir, \"alignment_input_sequences.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2611c07",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Remove sequences with undefined codons</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4083f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ambiguous_sequences = []\n",
    "ambiguous_sequences = []\n",
    "for sequence in focused_sequences:\n",
    "    if(\"X\" not in sequence.seq):\n",
    "        non_ambiguous_sequences.append(sequence)\n",
    "    else:\n",
    "        ambiguous_sequences.append(sequence)\n",
    "\n",
    "print(f\"Filtering out sequences with undefined residues.\\nOut of {len(focused_sequences)} sequences, {len(non_ambiguous_sequences)} remain.\")\n",
    "focused_sequences = non_ambiguous_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9549d0",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Remove sequences that are not Archaea or Bacteria</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_filename = \"../../../data/ASST_raw_sequences/ASSTs_annotated_sequences.json\"\n",
    "\n",
    "import json\n",
    "import tqdm\n",
    "YcaO_data = []\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    YcaO_data = json.load(f)\n",
    "\n",
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "taxonomy_index = 0\n",
    "taxonomy_selected_sequences = []\n",
    "branches_of_life = {}\n",
    "for i in tqdm.tqdm(range(0,len(focused_sequences)),desc=f\"Processing Sequence taxonomy\"):\n",
    "    sequence = non_ambiguous_sequences[i]\n",
    "    branch_of_life = get_item_by_accession(YcaO_data,sequence.id)[\"lineage\"][taxonomy_index].replace(\" \", \"_\")\n",
    "    if(branch_of_life == \"Bacteria\" or branch_of_life == \"Archaea\"):\n",
    "        taxonomy_selected_sequences.append(sequence)\n",
    "    else:\n",
    "        if(branch_of_life not in branches_of_life):\n",
    "            branches_of_life[branch_of_life] = 0\n",
    "        branches_of_life[branch_of_life] += 1\n",
    "\n",
    "print(f\"Filtering out sequences that do not come from Archaea or Bacteria.\\nOut of {len(focused_sequences)} sequences, {len(taxonomy_selected_sequences)} remain.\")\n",
    "print(f\"Sequences of other branches that were filtered out:\")\n",
    "print(json.dumps(branches_of_life, indent=4))\n",
    "\n",
    "focused_sequences = taxonomy_selected_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b16c47",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Remove sequences of abnormal size</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_sized_seqs = []\n",
    "size_filtered_sequences = []\n",
    "for seq in focused_sequences:\n",
    "    if(len(seq.seq) > 400 or len(seq.seq) < 200):\n",
    "        abnormal_sized_seqs.append(seq)\n",
    "    else:\n",
    "        size_filtered_sequences.append(seq)\n",
    "    \n",
    "pre_filter = [len(seq.seq) for seq in focused_sequences]\n",
    "filtered = [len(seq.seq) for seq in size_filtered_sequences]\n",
    "  \n",
    "bin_width = 5\n",
    "bins = range(0, max(pre_filter + filtered) + bin_width, bin_width)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.hist(pre_filter, bins, color='red', alpha=0.5, label='Pre-Filter')\n",
    "ax.hist(filtered, bins, color='blue', alpha=0.5, label='Filtered')\n",
    "ax.set_title(\"Filtering By Sequence Lengths\")\n",
    "ax.set_xlabel(\"Sequence Length\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Filtering out sequences with strange sizes.\\nOut of {len(focused_sequences)} sequences, {len(size_filtered_sequences)} remain.\")\n",
    "focused_sequences = size_filtered_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc43d66",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Save Sequences to File</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqIO.write(focused_sequences, alignment_input_filename, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d3453",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Create Phylogenetic Tree Data </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24867314-ba60-429d-abf0-06a2738d0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import copy\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b11f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_filename = \"../../../data/ASST_raw_sequences/ASSTs_annotated_sequences.json\"\n",
    "sequences_filename = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_70_ID_final_MSA.fa\"\n",
    "output_filename = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/tree_annotations.json\"\n",
    "output_filename_tsv = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/tree_annotations.tsv\"\n",
    "\n",
    "work_dir = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4894c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [seq for seq in SeqIO.parse(sequences_filename,\"fasta\")]\n",
    "\n",
    "general_json_data = []\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    general_json_data = json.load(f)\n",
    "    \n",
    "data = {}\n",
    "sequence_accessions = [seq.id for seq in sequences]\n",
    "for accession in sequence_accessions:\n",
    "    data[accession] = {}\n",
    "    \n",
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "def get_item_by_RefSeq_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_RefSeq'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "def add_data(header,d):\n",
    "    if(len(d) != len(sequences)):\n",
    "        raise Exception(\"The data supplied is the wrong length, it needs to be the same length as the total number of sequences!\")\n",
    "    for i in range(0,len(d)):\n",
    "        accession = sequence_accessions[i]\n",
    "        data[accession][header] = d[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd05fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Archaea', 'Bacteria']\n",
      "{'Archaea': '#1f77b4', 'Bacteria': '#ff7f0e'}\n"
     ]
    }
   ],
   "source": [
    "taxonomy_index = 0\n",
    "sequence_taxonomy = [get_item_by_accession(general_json_data,accession)[\"lineage\"][taxonomy_index].replace(\" \", \"_\") for accession in sequence_accessions]\n",
    "add_data(\"taxa\", sequence_taxonomy)\n",
    "\n",
    "import random\n",
    "import colorsys\n",
    "import matplotlib\n",
    "\n",
    "def generate_colors(sequence_taxonomy):\n",
    "    unique_taxa = list(set(sequence_taxonomy))\n",
    "    unique_taxa.sort()\n",
    "    print(unique_taxa)\n",
    "    taxa_colors = {}\n",
    "    sequence_colors = []\n",
    "    predefined_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    color_index = 0\n",
    "    for taxa in unique_taxa:\n",
    "        if color_index < len(predefined_colors):\n",
    "            taxa_colors[taxa] = predefined_colors[color_index]\n",
    "            color_index += 1\n",
    "        else:\n",
    "            h, s, v = random.random(), 0.5 + random.random() / 2.0, 0.4 + random.random() / 5.0\n",
    "            r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "            taxa_colors[taxa] = '#{:02x}{:02x}{:02x}'.format(int(r * 255), int(g * 255), int(b * 255))\n",
    "    print(taxa_colors)\n",
    "    for taxa in sequence_taxonomy:\n",
    "        sequence_colors.append(taxa_colors[taxa])\n",
    "    return sequence_colors\n",
    "\n",
    "\n",
    "sequence_colors = generate_colors(sequence_taxonomy)\n",
    "add_data(\"color\",sequence_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e2e929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 02/27/2024 15:05:07\n",
      "New DB name:   /files/data/ASST_processed_sequences/23_02_24_Quick_Tree/db_data/my_blast_db\n",
      "New DB title:  ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/db_data/db_sequences.fa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 805 sequences in 0.087117 seconds.\n",
      "\n",
      "\n",
      "1/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/3ELQ/sequence.fa\n",
      "Got results:\n",
      "['A0A444R377', 'A0A447PXQ2', 'A0A744VXH3', 'R5Q6T1', 'A0A831LQ00', 'A0A139JVE0', 'H3KH99', 'A0A381DJT3', 'A0A659PJW9', 'A0A2R4P1T2', 'A0A496LFW1', 'A0A139JS08']\n",
      "2/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/ASTB/sequence.fa\n",
      "Got results:\n",
      "['I4A3U7', 'A0A942KLW0', 'A0A8J7RUW5', 'A0A8J7RRZ2', 'A0A1Y4RY76', 'A0A2V2EI48', 'A0A143WX81', 'A0A7X1LV92', 'A0A1Y4RZ00', 'A0A4V5NPL0', 'A0A2V3Y1W7', 'A0A1C5Y9T5', 'A0A1C6AJ16', 'A0A2L1GLL8', 'A0A1Y4CK53', 'A0A350X2F4', 'A0A5N1BVY2', 'A0A847E3G1', 'A0A120IDT5', 'A0A120I9M2', 'A0A133Y078', 'R5MAH8', 'A0A9E1MHA4', 'A0A9D5NIL9', 'A0A832Q5P7', 'A0A929YMS1', 'A0A1C5VE70', 'A0A7H8SA86', 'A0A9E1FKL6', 'A0A242CYM0', 'A0A9E2KCY3', 'A0A0H4KKD6', 'A0A0C2E946', 'A0A9C8KVV4', 'A0A0U4EHI6', 'A0A1H9ZFP1', 'A0A7X1C8Q4', 'A0A6N8HLQ5', 'A0A2N1SMR4', 'A0A9D5XP24', 'A0A0X8G280']\n",
      "3/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_1/sequence.fa\n",
      "Got results:\n",
      "['A0A744VXH3', 'A0A447PXQ2', 'R5Q6T1', 'A0A444R377', 'A0A659PJW9', 'A0A831LQ00', 'A0A381DJT3', 'H3KH99', 'A0A2R4P1T2', 'A0A496LFW1', 'A0A139JVE0']\n",
      "4/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_10/sequence.fa\n",
      "Got results:\n",
      "['R5MAH8', 'R5MAH8', 'A0A350X2F4', 'A0A350X2F4', 'A0A120IDT5', 'A0A120IDT5', 'A0A9E1MHA4', 'A0A9E1MHA4', 'A0A143WX81', 'A0A942KLW0', 'A0A942KLW0', 'A0A1C6AJ16', 'A0A1C6AJ16', 'A0A7X1LV92', 'A0A1Y4RY76', 'A0A8J7RRZ2', 'A0A8J7RRZ2', 'A0A847E3G1', 'A0A9E1FKL6', 'A0A2V2EI48', 'A0A1Y4CK53', 'A0A1C5Y9T5', 'A0A1C5Y9T5', 'A0A9D5NIL9', 'A0A2V3Y1W7', 'I4A3U7', 'A0A2L1GLL8', 'A0A8J7RUW5', 'A0A4V5NPL0', 'A0A4V5NPL0', 'A0A1Y4RZ00', 'A0A133Y078', 'A0A7H8SA86', 'A0A7H8SA86', 'A0A120I9M2', 'A0A929YMS1', 'A0A2N1SMR4', 'A0A9E2KCY3', 'A0A5N1BVY2', 'A0A9C8KVV4', 'A0A1C5VE70', 'A0A6N8HLQ5', 'A0A6N8HLQ5', 'A0A832Q5P7', 'A0A0H4KKD6', 'A0A0H4KKD6', 'A0A7X1C8Q4', 'A0A7X1C8Q4', 'A0A1H9ZFP1', 'A0A1H9ZFP1', 'A0A0U4EHI6', 'A0A0U4EHI6', 'A0A0C2E946', 'A0A0C2E946', 'A0A556PMN6', 'A0A556PMN6', 'A0A0R1SFG1', 'A0A0R1SFG1', 'A0A6C2C485', 'A0A242CYM0', 'A0A242CYM0', 'A0A9D8VNM4', 'A0A9D5XP24', 'A0A192GXY4', 'A0A6I3NDS9', 'A0A6I3NDS9', 'A0A4Q7IXA6', 'A0A0D4CJN7', 'A0A0D4CJN7', 'A0A1E5SYL0', 'A0A831VQY4', 'A4ANG2', 'A0A0R1S0I6', 'A0A4Z0RUL0', 'A0A4Q0VH81', 'A0A3B9HJ80', 'A0A0R2VB00', 'A0A4P5PLK6', 'A0A4P5PLK6', 'A0A1L6H7U9', 'A0A1L6H7U9', 'A0A6L9EDV2', 'A0A0R2G579', 'A0A1B6YDK5', 'A0A2E2ZBD1', 'A0A958YZE8', 'A0A523LA79', 'A0A520Z680', 'A0A2E1HQ72']\n",
      "5/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_11/sequence.fa\n",
      "Got results:\n",
      "['A0A2N1SMR4', 'A0A9D5XP24', 'A0A9C8KVV4', 'A0A9E1FKL6', 'A0A9E2KCY3', 'A0A1H9ZFP1', 'A0A350X2F4', 'R5MAH8', 'A0A120IDT5', 'A0A7X1LV92', 'A0A2V3Y1W7', 'A0A831VQY4', 'A0A7H8SA86', 'A0A9E1MHA4', 'A0A1C6AJ16', 'A0A847E3G1', 'A0A143WX81', 'A0A0H4KKD6', 'A0A9D5NIL9', 'A0A1C5Y9T5', 'A0A0C2E946', 'A0A6N8HLQ5', 'A0A942KLW0', 'A0A2V2EI48', 'A0A8J7RUW5', 'A0A8J7RRZ2', 'A0A242CYM0', 'A0A6P0U7V2', 'A0A556PMN6', 'A0A2L1GLL8', 'A0A4V5NPL0', 'A0A6L9EDV2', 'A0A1Y4RZ00', 'A0A0R1Y7S5', 'A0A192GXY4', 'A0A7K2CAD5', 'A0A0R2VB00', 'A0A1Y4RY76', 'A0A929YMS1', 'A0A3B9HJ80', 'A0A1Y4CK53', 'A0A4P5PLK6', 'A0A1E5SYL0', 'A0A4Q0VH81', 'A0A7Y2ZLA0', 'A0A9D8VNM4', 'A0A523LA79', 'A0A958YZE8', 'A0A133Y078', 'A0A1L6H7U9', 'A0A5N1BVY2', 'A0A1B6YDK5', 'A0A5C7MJG7', 'A0A2E3YQ63', 'A0A120I9M2', 'A0A0D4CJN7', 'A0A832Q5P7', 'A0A2R7KUM8', 'A0A1Z8X520', 'A0A660DT55', 'A0A2D8CHW1', 'A0A069SI87', 'C2G194', 'A0A356X4R3', 'A0A959I2J5']\n",
      "6/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_12/sequence.fa\n",
      "Got results:\n",
      "['A0A9E1FKL6', 'A0A9E2KCY3', 'A0A2N1SMR4', 'A0A9C8KVV4', 'A0A9D5XP24', 'R5MAH8', 'A0A9E1MHA4', 'A0A143WX81', 'A0A120IDT5', 'A0A2V3Y1W7', 'A0A350X2F4', 'A0A942KLW0', 'A0A4V5NPL0', 'A0A1Y4RZ00', 'A0A1H9ZFP1', 'A0A7X1LV92', 'A0A9D5NIL9', 'A0A1C5Y9T5', 'A0A7X1C8Q4', 'A0A8J7RRZ2', 'A0A8J7RUW5', 'A0A1Y4CK53', 'A0A2E1HQ72', 'A0A1Y4RY76', 'A0A0H4KKD6', 'A0A847E3G1', 'A0A1C6AJ16', 'I4A3U7', 'A0A6P0U7V2', 'A0A6N8HLQ5', 'A0A133Y078', 'A0A7H8SA86', 'A0A5N1BVY2', 'A0A831VQY4', 'A0A929YMS1', 'A0A2V2EI48', 'A0A958YZE8', 'A0A0U4EHI6', 'A0A832Q5P7', 'A0A2L1GLL8', 'A4ANG2', 'A0A2E2ZBD1', 'A0A120I9M2', 'A0A556PMN6', 'A0A2D8CHW1', 'A0A242CYM0', 'A0A520Z680', 'A0A0C2E946', 'A0A1E5SYL0', 'A0A7Y2ZLA0', 'A0A523LA79', 'A0A192GXY4', 'A0A0R2VB00', 'A0A2R7KUM8', 'A0A1Z8X520', 'A0A6C8Y9U0', 'A0A356X4R3', 'A0A5C7MJG7', 'A0A4Z0RUL0', 'A0A0D4CJN7', 'A0A6C2C485', 'A0A0R2G579']\n",
      "7/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_13/sequence.fa\n",
      "Got results:\n",
      "['A0A1Z8X520', 'A0A523LA79', 'A0A2E3YQ63', 'A0A2E7F987', 'A0A944TDQ2', 'A0A945I7H3', 'A0A944TAJ9', 'A0A2E7PMB5', 'A0A1Z9J8T7', 'A0A1Z9EXH8', 'A0A1W7MCM3', 'A0A6L7KQW2', 'A0A2N1SMR4']\n",
      "8/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_14/sequence.fa\n",
      "Got results:\n",
      "['']\n",
      "9/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_15/sequence.fa\n",
      "Got results:\n",
      "['']\n",
      "10/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_16/sequence.fa\n",
      "Got results:\n",
      "['A0A2E7PMB5', 'A0A2E7F987', 'A0A944TDQ2', 'A0A1W7MCM3', 'A0A6L7KQW2', 'A0A2E3YQ63', 'A0A523LA79', 'A0A945I7H3', 'A0A1Z8X520', 'A0A944TAJ9', 'A0A1Z9J8T7', 'A0A1Z9EXH8']\n",
      "11/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_17/sequence.fa\n",
      "Got results:\n",
      "['A0A2T5XX56', 'A0A0M4GJ27', 'A0A125S443', 'A0A840CGS5', 'A0A2T4T6I5']\n",
      "12/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_18/sequence.fa\n",
      "Got results:\n",
      "['']\n",
      "13/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_19/sequence.fa\n",
      "Got results:\n",
      "['A0A1Z9EXH8', 'A0A944TAJ9', 'A0A945I7H3', 'A0A1Z9J8T7', 'A0A523LA79', 'A0A2E3YQ63', 'A0A6L7KQW2', 'A0A1Z8X520', 'A0A2E7F987', 'A0A2E7PMB5', 'A0A1W7MCM3', 'A0A944TDQ2']\n",
      "14/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_2/sequence.fa\n",
      "Got results:\n",
      "['A0A5X6J2C7', 'A0A7X1AP87', 'A0A084D6C3', 'A0A3R9VEZ7', 'A0A7K3DXC2', 'A0A2K8SZG1', 'Q1Q634', 'A0A2N0KJY1', 'A0A9E4WWF8', 'A0A945I3D1', 'A0A2E2YS76', 'A0A9E4RBD6', 'A0A1Z8RGR7', 'A0A2E9TAV3', 'A0A6L7JH24']\n",
      "15/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_20/sequence.fa\n",
      "Got results:\n",
      "['A0A523LA79', 'A0A1Z8X520', 'A0A2E3YQ63', 'A0A945I7H3', 'A0A944TAJ9', 'A0A2E7F987', 'A0A1Z9J8T7', 'A0A944TDQ2', 'A0A1Z9EXH8', 'A0A2E7PMB5', 'A0A1W7MCM3', 'A0A6L7KQW2', 'A0A9C8KVV4', 'A0A2N1SMR4', 'A0A9D5XP24']\n",
      "16/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_21/sequence.fa\n",
      "Got results:\n",
      "['A0A523LA79', 'A0A2E3YQ63', 'A0A1Z8X520', 'A0A2E7PMB5', 'A0A944TDQ2', 'A0A2E7F987', 'A0A945I7H3', 'A0A944TAJ9', 'A0A1Z9EXH8', 'A0A1W7MCM3', 'A0A6L7KQW2', 'A0A1Z9J8T7', 'A0A9E1MHA4', 'A0A9C8KVV4', 'A0A7H8SA86']\n",
      "17/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_22/sequence.fa\n",
      "Got results:\n",
      "['A0A9E1MHA4', 'A0A9D5NIL9', 'A0A350X2F4', 'R5MAH8', 'A0A120IDT5', 'A0A847E3G1', 'A0A8J7RRZ2', 'I4A3U7', 'A0A929YMS1', 'A0A7X1LV92', 'A0A942KLW0', 'A0A143WX81', 'A0A1C5Y9T5', 'A0A1Y4CK53', 'A0A8J7RUW5', 'A0A1C6AJ16', 'A0A2V2EI48', 'A0A2V3Y1W7', 'A0A832Q5P7', 'A0A4V5NPL0', 'A0A2L1GLL8', 'A0A1Y4RZ00', 'A0A1Y4RY76', 'A0A120I9M2', 'A0A133Y078', 'A0A5N1BVY2', 'A0A1C5VE70', 'A0A0C2E946', 'A0A9E1FKL6', 'A0A4P5PLK6', 'A0A9E2KCY3', 'A0A7X1C8Q4', 'A0A1H9ZFP1', 'A0A556PMN6', 'A0A7H8SA86', 'A0A0H4KKD6', 'A0A831VQY4', 'A0A6N8HLQ5', 'A0A9D5XP24']\n",
      "18/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_3/sequence.fa\n",
      "Got results:\n",
      "['A0A564VM44', 'A0A126SX98', 'A0A229VZP9', 'A0A6N4TN13', 'A0A174DGL1', 'A0A412I1T3', 'A0A1Y4LX71', 'A0A9D2D917', 'A0A6N2UWB3', 'A0A2N5NI67', 'A0A938WXU7', 'A0A916Q924', 'C0C4I4', 'A0A9E0Z7S8', 'A0A2Y9BA24', 'A0A3A6DGZ6', 'A0A850HJJ1', 'A0A921I1Z2', 'A0A3C1CX68', 'A0A222W713', 'A0A3N0HY61', 'A0A0R2C9K7', 'A0A1Y4T107', 'A0A4V1EG37', 'A0A7X9NK71', 'A0A9D1WVM1', 'A0A3E3JYM6', 'A0A4R5YJ35', 'A0A6N2UKT2', 'A0A1Y4NCQ1', 'A0A1C5SCN0', 'A0A1Y3RQV4', 'A0A1Q6N5N3', 'A0A917GHK7', 'A0A173T580', 'A0A1Y4IUS7', 'A0A9D2P1R7', 'A0A3N0ARW7', 'A0A9D0ZU66', 'A6NSJ3', 'A0A1Q6N5M4', 'A0A173R0J6', 'A0A9D2SP63', 'A0A9D1D4V8', 'A0A096B9U3', 'A0A1Y3WQU8', 'A0A9Q4DAQ6', 'A0A9D2NUH6']\n",
      "19/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_4/sequence.fa\n",
      "Got results:\n",
      "['A0A2N5RC94', 'A0A2A4IQD0']\n",
      "20/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_5/sequence.fa\n",
      "Got results:\n",
      "['A0A2C9P412', 'A0A3V2KSV7', 'A0A0J8VM81', 'A0A3C0GZF0', 'A0A9J9GG12']\n",
      "21/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_6/sequence.fa\n",
      "Got results:\n",
      "['I4A3U7', 'A0A942KLW0', 'A0A8J7RUW5', 'A0A1Y4RY76', 'A0A8J7RRZ2', 'A0A7X1LV92', 'A0A2V2EI48', 'A0A143WX81', 'A0A1Y4RZ00', 'A0A4V5NPL0', 'A0A2V3Y1W7', 'A0A1C6AJ16', 'A0A1C5Y9T5', 'A0A1Y4CK53', 'A0A2L1GLL8', 'A0A350X2F4', 'A0A847E3G1', 'A0A120I9M2', 'A0A9E1MHA4', 'A0A120IDT5', 'A0A5N1BVY2', 'A0A133Y078', 'A0A9D5NIL9', 'R5MAH8', 'A0A832Q5P7', 'A0A929YMS1', 'A0A1C5VE70', 'A0A9E1FKL6', 'A0A7H8SA86', 'A0A242CYM0', 'A0A9E2KCY3', 'A0A0H4KKD6', 'A0A0C2E946', 'A0A0U4EHI6', 'A0A4P5PLK6', 'A0A6N8HLQ5', 'A0A9C8KVV4', 'A0A7X1C8Q4', 'A0A1H9ZFP1', 'A0A2N1SMR4', 'A0A0X8G280', 'A0A6L9EDV2']\n",
      "22/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_7/sequence.fa\n",
      "Got results:\n",
      "['A0A6N8HLQ5', 'A0A7H8SA86', 'A0A7X1C8Q4', 'A0A0C2E946', 'A0A1H9ZFP1', 'A0A0H4KKD6', 'A0A556PMN6', 'A0A0U4EHI6', 'A0A4P5PLK6', 'A0A242CYM0', 'A0A0R1S0I6', 'A0A192GXY4', 'A0A0R2G579', 'A0A0C1PVM3', 'A0A0D0Y4M8', 'A0A0R1SFG1', 'A0A0R1QFK7', 'A0A4R5NN22', 'A0A6C2C485', 'A0A0D4CJN7', 'A0A4Z0RUL0', 'A0A1L6H7U9', 'A0A0R1Y7S5', 'A0A4Q0VH81', 'A0A120IDT5', 'A0A350X2F4', 'A0A3R8GEX2', 'A0A8J7RUW5', 'A0A660DT55', 'A0A8J7RRZ2', 'A0A4Q7IXA6', 'A0A143WX81', 'A0A1C6AJ16', 'A0A942KLW0', 'A0A9E1MHA4', 'A0A9E1FKL6', 'A0A847E3G1', 'A0A1Y4CK53', 'A0A6I3NDS9', 'A0A9D5NIL9', 'A0A1C5Y9T5', 'A0A133Y078', 'R5MAH8', 'A0A7X1LV92', 'A0A2V2EI48', 'A0A2V3Y1W7', 'A0A9E2KCY3', 'A0A1C5VE70', 'A0A4V5NPL0', 'A0A2N1SMR4', 'A0A9D8VNM4', 'A0A1Y4RY76', 'A0A0X8G280', 'A0A9C8KVV4', 'A0A1Y4RZ00', 'A0A2L1GLL8', 'A0A959I2J5', 'I4A3U7', 'A0A7Y2ZLA0', 'A0A120I9M2', 'A0A9D5XP24', 'A0A6P0U7V2', 'A0A2D8CHW1', 'A4ANG2', 'A0A520Z680', 'A0A1B6YDK5', 'A0A6L9EDV2', 'A0A2E2ZBD1', 'A0A356X4R3', 'A0A1E5SYL0', 'A0A929YMS1', 'A0A1C5ZER4', 'A0A3B9HJ80', 'A0A5N1BVY2', 'A0A7K2CAD5', 'A0A2E1HQ72', 'A0A0R2VB00', 'A0A6C8Y9U0']\n",
      "23/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_8/sequence.fa\n",
      "Got results:\n",
      "['A0A1C5VE70', 'A0A350X2F4', 'A0A120IDT5', 'R5MAH8', 'I4A3U7', 'A0A9D5NIL9', 'A0A9E1MHA4', 'A0A7X1LV92', 'A0A1Y4CK53', 'A0A8J7RRZ2', 'A0A1C6AJ16', 'A0A847E3G1', 'A0A2V3Y1W7', 'A0A143WX81', 'A0A1Y4RZ00', 'A0A942KLW0', 'A0A1Y4RY76', 'A0A120I9M2', 'A0A2V2EI48', 'A0A133Y078', 'A0A1C5Y9T5', 'A0A8J7RUW5', 'A0A2L1GLL8', 'A0A4V5NPL0', 'A0A5N1BVY2', 'A0A832Q5P7', 'A0A929YMS1', 'A0A7X1C8Q4', 'A0A9E1FKL6', 'A0A7H8SA86', 'A0A0H4KKD6', 'A0A0J1G5P4', 'A0A0C2E946', 'A0A4Q0VH81', 'A0A6N8HLQ5', 'A0A3B9HJ80']\n",
      "24/24 Processing ../../../data/ASST_raw_sequences/interesting_sequences/Roscoff_sequences/ASST_9/sequence.fa\n",
      "Got results:\n",
      "['R5MAH8', 'R5MAH8', 'A0A350X2F4', 'A0A350X2F4', 'A0A120IDT5', 'A0A120IDT5', 'A0A7X1LV92', 'A0A847E3G1', 'A0A9E1MHA4', 'A0A9E1MHA4', 'A0A143WX81', 'A0A1Y4RY76', 'A0A1Y4RY76', 'A0A7X1C8Q4', 'A0A7X1C8Q4', 'A0A9D5NIL9', 'A0A9D5NIL9', 'A0A8J7RRZ2', 'A0A8J7RRZ2', 'A0A1Y4RZ00', 'A0A1C6AJ16', 'A0A942KLW0', 'A0A942KLW0', 'A0A7H8SA86', 'A0A7H8SA86', 'A0A2V3Y1W7', 'A0A2V3Y1W7', 'I4A3U7', 'A0A4P5PLK6', 'A0A0U4EHI6', 'A0A0U4EHI6', 'A0A929YMS1', 'A0A1Y4CK53', 'A0A1Y4CK53', 'A0A4V5NPL0', 'A0A4V5NPL0', 'A0A120I9M2', 'A0A0C2E946', 'A0A0C2E946', 'A0A8J7RUW5', 'A0A8J7RUW5', 'A0A6N8HLQ5', 'A0A6N8HLQ5', 'A0A556PMN6', 'A0A556PMN6', 'A0A1C5Y9T5', 'A0A2V2EI48', 'A0A2L1GLL8', 'A0A5N1BVY2', 'A0A9E1FKL6', 'A0A1H9ZFP1', 'A0A832Q5P7', 'A0A133Y078', 'A0A0H4KKD6', 'A0A0H4KKD6', 'A0A9E2KCY3', 'A0A242CYM0', 'A0A242CYM0', 'A0A831VQY4', 'A0A1C5VE70', 'A0A0R1SFG1', 'A0A0R2G579', 'A0A0R2G579', 'A0A2N1SMR4', 'A0A9D8VNM4', 'A0A3B9HJ80', 'A0A4Q0VH81', 'A0A1L6H7U9', 'A0A0R2VB00', 'A0A2D8CHW1', 'A0A1E5SYL0', 'A0A192GXY4', 'A0A6C2C485', 'A0A9C8KVV4', 'A0A356X4R3', 'A0A6L9EDV2', 'A0A4Q7IXA6', 'A0A4Z0RUL0', 'A0A0R1S0I6', 'A0A0D4CJN7']\n"
     ]
    }
   ],
   "source": [
    "#Load special sequences and find them in the tree\n",
    "# define the starting directory\n",
    "root_dir = \"../../../data/ASST_raw_sequences/interesting_sequences/\"\n",
    "\n",
    "import os\n",
    "\n",
    "fasta_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if  \"sequence.fa\" in file.lower():\n",
    "            fasta_path = os.path.join(dirpath, file)\n",
    "            name = os.path.basename(os.path.dirname(fasta_path))\n",
    "            \n",
    "            # append the fasta path and the name to the list as a tuple\n",
    "            fasta_paths.append((fasta_path, name))\n",
    "\n",
    "\n",
    "db_dir = os.path.join(work_dir,\"db_data/\")\n",
    "db_filename = os.path.join(db_dir,\"my_blast_db\")\n",
    "db_sequences_filename = os.path.join(db_dir,\"db_sequences.fa\")\n",
    "\n",
    "if not os.path.exists(db_dir):\n",
    "    os.mkdir(db_dir)\n",
    "else:\n",
    "    !rm -rf $db_dir\n",
    "    os.mkdir(db_dir)\n",
    "\n",
    "\n",
    "def get_full_sequence(seq_id):\n",
    "    entry = get_item_by_accession(general_json_data,seq_id)\n",
    "    seq = Seq(entry[\"seq\"])\n",
    "    return SeqRecord(seq, id=entry[\"Accession_Interpro\"], description=\"\")\n",
    "    \n",
    "db_sequences = []\n",
    "for accession in sequence_accessions:\n",
    "    db_sequences.append(get_full_sequence(accession))\n",
    "SeqIO.write(db_sequences, db_sequences_filename, \"fasta\")\n",
    "\n",
    "!makeblastdb -in {db_sequences_filename} -dbtype prot -out {db_filename}\n",
    "\n",
    "import subprocess\n",
    "\n",
    "path_accessions = []\n",
    "for i in range(0,len(fasta_paths)):\n",
    "    fasta_path = fasta_paths[i][0]\n",
    "    print(f\"{i+1}/{len(fasta_paths)} Processing {fasta_path}\")\n",
    "    shortened_path = fasta_paths[i][1]\n",
    "    output = subprocess.run(f\"blastp -db {db_filename} -query {fasta_path} -outfmt '6 sseqid' -evalue 1e-50\", shell=True, capture_output=True)\n",
    "    accession_numbers = output.stdout.decode().strip().split(\"\\n\")\n",
    "    print(f\"Got results:\\n{accession_numbers}\")\n",
    "    path_accessions.append((shortened_path, accession_numbers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a163b7eb-a656-463b-b6e8-e2109335c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_similar_sequence_name_if_any(accession,path_accessions):\n",
    "    result = []\n",
    "    for path in path_accessions:\n",
    "        if accession in path[1]:\n",
    "            result.append((path[1].index(accession),path[0]))\n",
    "    return result\n",
    "\n",
    "similar_accessions = list(itertools.chain(*[path[1] for path in path_accessions]))\n",
    "\n",
    "sequence_characterised = [\"Y\" if accession in similar_accessions else \"N\" for accession in sequence_accessions]\n",
    "sequence_related_sequence = [get_similar_sequence_name_if_any(accession,path_accessions) for accession in sequence_accessions]\n",
    "\n",
    "\n",
    "def get_closest_sequence_if_any(accession,path_accessions):\n",
    "    for important_sequence_info in path_accessions:\n",
    "        if important_sequence_info[1] != []:\n",
    "            top_hit =  important_sequence_info[1][0]\n",
    "            if top_hit == accession:\n",
    "                return important_sequence_info[0]\n",
    "    return \"_\" \n",
    "    \n",
    "important_sequences = [get_closest_sequence_if_any(accession,path_accessions) for accession in sequence_accessions]\n",
    "\n",
    "\n",
    "# add_data(\"related_to_known_seq\",sequence_characterised)\n",
    "# add_data(\"related_seq\",sequence_related_sequence)\n",
    "add_data(\"important_seq\",important_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af80a0a0-c925-4802-b126-5e9eb68eee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence size\n",
    "sequences_sizes = [len(get_item_by_accession(general_json_data,accession)[\"seq\"]) for accession in sequence_accessions]\n",
    "\n",
    "add_data(\"sequence_length\",sequences_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01407177-ca31-44d5-a7af-e6ba87c8613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common Domains:\n",
      "\n",
      "IPR010262\n",
      "PTHR35340\n",
      "IPR011047\n",
      "IPR035391\n",
      "IPR038477\n",
      "IPR026444\n",
      "PS51257\n",
      "SSF63829\n",
      "IPR013783\n",
      "IPR011044\n"
     ]
    }
   ],
   "source": [
    "# Domain Info\n",
    "domain_info_filename = \"../../../data/ASST_raw_sequences/ASSTs_domain_data.json\"\n",
    "\n",
    "domain_info = []\n",
    "with open(domain_info_filename, 'r') as f:\n",
    "    domain_info = json.load(f)\n",
    "\n",
    "def get_domain_info(accession):\n",
    "    for element in domain_info:\n",
    "        if(element[\"Accession_Interpro\"] == accession):\n",
    "            if(\"error\" in element[\"domains\"]):\n",
    "                return []\n",
    "            return element[\"domains\"]\n",
    "    return []\n",
    "    \n",
    "sequence_domains = [get_domain_info(accession) for accession in sequence_accessions]\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "unique_domains = set(chain.from_iterable(sequence_domains))\n",
    "\n",
    "def generate_colour_from_set(value,set_of_values):\n",
    "    predefined_colors = [ '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    value_index = list(set_of_values).index(value)\n",
    "    rng_preset_seed = 42\n",
    "    rng_seed = rng_preset_seed + value_index\n",
    "    random.seed(rng_seed)\n",
    "    if value_index < len(predefined_colors):\n",
    "        return predefined_colors[value_index]\n",
    "    else:\n",
    "        h, s, v = random.random(), 0.5 + random.random() / 2.0, 0.4 + random.random() / 5.0\n",
    "        r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "        return '#{:02x}{:02x}{:02x}'.format(int(r * 255), int(g * 255), int(b * 255))\n",
    "\n",
    "\n",
    "all_domains = list(chain.from_iterable(sequence_domains))\n",
    "# Count occurrences of each domain\n",
    "domain_counter = Counter(all_domains)\n",
    "\n",
    "# Get the 10 most common domains\n",
    "top_10_domains = domain_counter.most_common(10)\n",
    "\n",
    "# Extract just the domain names from the Counter results\n",
    "most_common_domains = [domain for domain, count in top_10_domains]\n",
    "\n",
    "print(\"Top 10 Most Common Domains:\\n\")\n",
    "for domain in most_common_domains:\n",
    "    print(domain)\n",
    "    domain_in_sequence = [\"Y\" for domains in sequence_domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d53cd3-df67-4c13-babe-d4770ebeaf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data successfully written to ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/tree_annotations.tsv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(output_filename, \"w\") as file:\n",
    "    # Write the dictionary to the file in JSON format\n",
    "    json.dump(data, file)\n",
    "\n",
    "import csv\n",
    "def convert_json_to_tsv(data, output_path):\n",
    "    # Check if all elements have the same fields\n",
    "    fields = set()\n",
    "    for item in data.values():\n",
    "        for key in item.keys():\n",
    "            fields.add(key)\n",
    "\n",
    "    for item in data.values():\n",
    "        if set(item.keys()) != fields:\n",
    "            raise ValueError(\"All elements in the dictionary must have the same fields.\")\n",
    "\n",
    "    # Prepare data for writing to TSV\n",
    "    rows = []\n",
    "    for seq_id, details in data.items():\n",
    "        row = [seq_id] + [details[field] for field in sorted(details)]\n",
    "        rows.append(row)\n",
    "\n",
    "    # Define header based on fields\n",
    "    header = [\"Name\"] + sorted(list(fields))\n",
    "\n",
    "    # Write to TSV file\n",
    "    with open(output_path, 'wt', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    return f\"Data successfully written to {output_path}\"\n",
    "\n",
    "convert_json_to_tsv(data,output_filename_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load RODEO data\n",
    "rodeo_files = []\n",
    "for subdir, dirs, files in os.walk(rodeo_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"main_co_occur.csv\"):\n",
    "            rodeo_files.append(os.path.join(subdir, file))\n",
    "            \n",
    "rodeo_data = []\n",
    "for file in rodeo_files:\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        rows = [row for row in reader]\n",
    "        rodeo_data.extend(rows)\n",
    "\n",
    "        \n",
    "processed_rodeo_data = {}\n",
    "for i in tqdm(range(0,len(rodeo_data)),desc=\"Processing Rodeo Data\"):\n",
    "    row = rodeo_data[i]\n",
    "    if(row[\"Query\"] not in processed_rodeo_data):\n",
    "        processed_rodeo_data[row[\"Query\"]] = []\n",
    "    contents = []\n",
    "    #print(row)\n",
    "    for key, value in row.items():\n",
    "        if key is not None:\n",
    "            if \"PfamID\" in key and value is not None:\n",
    "                contents.append(value)\n",
    "        elif isinstance(value,list):\n",
    "            for v in value:\n",
    "                if re.search(r'PF\\d{5}', v):\n",
    "                    contents.append(v)\n",
    "    processed_rodeo_data[row[\"Query\"]].extend(contents)\n",
    "\n",
    "def get_sequence_ID_present(Pfam_ID):\n",
    "    RefSeq_ids_with_ID = []\n",
    "    RefSeq_ids_without_ID = []\n",
    "    for key, value in processed_rodeo_data.items():\n",
    "        if Pfam_ID in value:\n",
    "            RefSeq_ids_with_ID.append(key)\n",
    "        else:\n",
    "            RefSeq_ids_without_ID.append(key)\n",
    "\n",
    "    sequence_ID_present = []\n",
    "\n",
    "    for i in tqdm(range(0,len(sequence_accessions)),desc=f\"Scanning sequences for {Pfam_ID}\"):\n",
    "        accession = sequence_accessions[i]\n",
    "        accession_data = get_item_by_accession(YcaO_data, accession)\n",
    "        ID_present = \"U\"\n",
    "        if(\"Accession_RefSeq\" in accession_data):\n",
    "            refSeq = accession_data[\"Accession_RefSeq\"]\n",
    "            if(refSeq in RefSeq_ids_with_ID):\n",
    "                ID_present = \"Y\"\n",
    "            elif(refSeq in RefSeq_ids_without_ID):\n",
    "                ID_present = \"N\"\n",
    "        sequence_ID_present.append(ID_present)\n",
    "    return sequence_ID_present\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee08042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859aa4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate all sequences whether or not they were tridomain\n",
    "E1_sequences = [val[\"Accession_Interpro\"] for val in E1_data]\n",
    "sequence_contains_E1 = [\"Y\" if accession.split(\".\")[0] in E1_sequences else \"N\" for accession in sequence_accessions]\n",
    "add_data(\"contains_E1\",sequence_contains_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0857f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(additional_data_filename, \"w\") as file:\n",
    "    # Write the dictionary to the file in JSON format\n",
    "    json.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aeab4c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Diagrams for fun </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "all_annotations_filename = \"../raw_sequences/interpro_all_YcaO_annotated.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586de27e",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25778ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences_filename = \"../processed_sequences/initial_dataset/alignment_input_sequences.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [seq for seq in SeqIO.parse(input_sequences_filename,\"fasta\")]\n",
    "\n",
    "\n",
    "sequence_accessions = [seq.id for seq in sequences]\n",
    "\n",
    "YcaO_data = []\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    YcaO_data = json.load(f)\n",
    "           \n",
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_info = {}\n",
    "for i in tqdm(range(0,len(sequence_accessions))):\n",
    "    accession = sequence_accessions[i]\n",
    "    taxonomy = get_item_by_accession(YcaO_data,accession)[\"lineage\"]\n",
    "    if taxonomy[0] not in taxonomy_info:\n",
    "        taxonomy_info[taxonomy[0]] = {}\n",
    "    if taxonomy[1] not in taxonomy_info[taxonomy[0]]:\n",
    "        taxonomy_info[taxonomy[0]][taxonomy[1]] = 0\n",
    "    taxonomy_info[taxonomy[0]][taxonomy[1]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1):\n",
    "    top_level = []\n",
    "    first_level = []\n",
    "    vals = []\n",
    "    for key in taxonomy_info.keys():\n",
    "        top_level.append(key)\n",
    "        vals.append([])\n",
    "        keys2 = list(taxonomy_info[key].keys())\n",
    "        random.shuffle(keys2)\n",
    "        for key2 in keys2:\n",
    "            if(taxonomy_info[key][key2] > 30):\n",
    "                first_level.append(key2)\n",
    "                vals[-1].append((taxonomy_info[key][key2]))\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    size = 0.3\n",
    "\n",
    "    inner_layer = [sum(x) for x in vals]\n",
    "    outer_layer = [item for sublist in vals for item in sublist]\n",
    "\n",
    "    inner_colors = ['#1f77b4', '#ff7f0e']\n",
    "\n",
    "    bacteria_colors = [\"#1f77b4\"]*len(vals[0])\n",
    "    archaea_colors = [\"#ff7f0e\"]*len(vals[1])\n",
    "\n",
    "    bacteria_colors = [color+'{:02x}'.format(int(random.uniform(0.2, 1) * 255)) for color in bacteria_colors]\n",
    "    archaea_colors = [color+'{:02x}'.format(int(random.uniform(0.3, 1) * 255)) for color in archaea_colors]\n",
    "    print(bacteria_colors)\n",
    "    outer_colors = bacteria_colors+archaea_colors\n",
    "\n",
    "    ax.pie(outer_layer, radius=1, colors=outer_colors,\n",
    "           labels=first_level, textprops={'fontsize': 13},\n",
    "           wedgeprops=dict(width=size, edgecolor='w'))\n",
    "\n",
    "    ax.pie(inner_layer, radius=1-size, colors=inner_colors,\n",
    "           labels=top_level, textprops={'fontsize': 20},labeldistance=.6,\n",
    "           wedgeprops=dict(width=size, edgecolor='w'))\n",
    "\n",
    "    ax.set(aspect=\"equal\", title='Taxonomy of YcaO sequences')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
