{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a97756b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Create & Validate MSA </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d4a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio import AlignIO\n",
    "\n",
    "YcaO_HMM_filename = \"../../../data/ASST_raw_sequences/PF05935.hmm\"\n",
    "\n",
    "work_dir = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/\"\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "clustalo_output_filename = os.path.join(work_dir,\"clustalo_MSA.fa\")\n",
    "mafft_output_filename = os.path.join(work_dir,\"mafft_MSA.fa\")\n",
    "hmm_output_filename = os.path.join(work_dir,\"hmm_MSA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23682955",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define algorithm and input sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92543015",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_input_filename = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/alignment_input_sequences.txt\"#Don't change me unless you know what you're doing\n",
    "MSA_algorithm = \"clustalo\" #options include mafft, clustalo, hmmalign\n",
    "\n",
    "\n",
    "custom_alignment_filename = os.path.join(work_dir,\"custom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba11b5",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Run MSA algorithm</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23d494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 threads\n",
      "Read 6248 sequences (type: Protein) from ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/alignment_input_sequences.txt\n",
      "Using 158 seeds (chosen with constant stride from length sorted seqs) for mBed (from a total of 6248 sequences)\n",
      "Calculating pairwise ktuple-distances...\n",
      "Ktuple-distance calculation progress done. CPU time: 103.32u 0.11s 00:01:43.43 Elapsed: 00:00:20\n",
      "WARNING: BisectingKmeans(): Can't split cluster no. 35 which has 115 objects any further. Hope it's not too big and doesn't slow things down.\n",
      "mBed created 125 cluster/s (with a minimum of 1 and a soft maximum of 100 sequences each)\n",
      "Distance calculation within sub-clusters done. CPU time: 24.68u 0.03s 00:00:24.71 Elapsed: 00:00:04\n",
      "Guide-tree computation (mBed) done.\n",
      "Progressive alignment progress done. CPU time: 1559.97u 4.28s 00:26:04.25 Elapsed: 00:06:51\n",
      "Alignment written to ../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_MSA.fa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if (MSA_algorithm == \"mafft\"):\n",
    "    !mafft  --distout {MSA_input_filename} > $mafft_output_filename\n",
    "elif (MSA_algorithm == \"clustalo\"):\n",
    "    !clustalo -i {MSA_input_filename} --hmm-in={YcaO_HMM_filename} -o {clustalo_output_filename} -v\n",
    "elif (MSA_algorithm == \"hmmalign\"):\n",
    "    !hmmalign --trim --amino -o {hmm_output_filename+\".sto\"} {YcaO_HMM_filename} {MSA_input_filename}\n",
    "    alignment = AlignIO.read(hmm_output_filename+\".sto\", \"stockholm\")\n",
    "    for i in range(0,len(alignment)):\n",
    "        alignment[i].seq = Seq((str(alignment[i].seq)).upper())\n",
    "    AlignIO.write(alignment, hmm_output_filename+\".fa\", \"fasta\")\n",
    "elif (MSA_algorithm == \"custom\"):\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b69c9c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Rerun MSA for phylogenetic analysis </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc119bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "YcaO_HMM_filename = \"../../../data/ASST_raw_sequences/PF05935.hmm\"\n",
    "\n",
    "\n",
    "def remove_gaps(seq_record):\n",
    "    seq = seq_record.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    return SeqRecord(seq_without_gaps, id=seq_record.id, description=seq_record.description)\n",
    "\n",
    "work_dir = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/\"\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521cf13",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define algorithm and input sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0112507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_input_filename = \"../../../data/ASST_processed_sequences/23_02_24_Quick_Tree/clustalo_5_per_cluster_70_ID_initial_MSA.fa\"\n",
    "MSA_algorithm = \"clustalo\" #options include mafft, clustalo, hmmalign\n",
    "output_MSA_filename = os.path.join(work_dir,\"clustalo_5_per_cluster_70_ID_final_MSA.fa\")\n",
    "\n",
    "hmm_temp_filename = os.path.join(work_dir,\"temp_hmm.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1b1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer:hhalignment-C.h:3120: profile has no leading and/or trailing residues (h=-1:t=568:#=805)\n",
      "WARNING: FIXME: Using only first of 2 HMMs (needs implementation)\n"
     ]
    }
   ],
   "source": [
    "if (MSA_algorithm == \"mafft\"):\n",
    "    !mafft  --distout {MSA_input_filename} > $mafft_output_filename\n",
    "elif (MSA_algorithm == \"clustalo\"):\n",
    "    !clustalo -i {MSA_input_filename} --hmm-in={YcaO_HMM_filename} -o {output_MSA_filename}\n",
    "elif (MSA_algorithm == \"hmmalign\"):\n",
    "    output_MSA_filename = output_MSA_filename.split(\".fa\")[0]\n",
    "    sequences = [seqrec for seqrec in SeqIO.parse(MSA_input_filename,\"fasta\")]\n",
    "    ungapped_sequences = []\n",
    "    for seq in sequences:\n",
    "        ungapped_sequences.append(remove_gaps(seq))\n",
    "    SeqIO.write(ungapped_sequences, hmm_temp_filename, \"fasta\")\n",
    "    !hmmalign --trim --amino -o {output_MSA_filename+\".sto\"} {YcaO_HMM_filename} {hmm_temp_filename}\n",
    "    alignment = AlignIO.read(output_MSA_filename+\".sto\", \"stockholm\")\n",
    "    for i in range(0,len(alignment)):\n",
    "        alignment[i].seq = Seq((str(alignment[i].seq)).upper())\n",
    "    AlignIO.write(alignment, output_MSA_filename+\".fa\", \"fasta\")\n",
    "elif (MSA_algorithm == \"custom\"):\n",
    "    print()\n",
    "else:\n",
    "    raise Exception(\"Wrong MSA algorithm selected, options are: mafft, clustalo or hmmalign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f63018",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Validate MSA </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb7914f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../raw_sequences/secondary_structure_for_MSA_validation.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m helix_data_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../raw_sequences/secondary_structure_for_MSA_validation.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m helix_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhelix_data_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m     helix_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../raw_sequences/secondary_structure_for_MSA_validation.json'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch\n",
    "mpl.rcParams['figure.dpi']= 600\n",
    "\n",
    "helix_data_filename = \"../raw_sequences/secondary_structure_for_MSA_validation.json\"\n",
    "helix_data = []\n",
    "with open(helix_data_filename, \"r\") as f:\n",
    "    helix_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99f69e",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define MSA sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_filename = mafft_output_filename\n",
    "\n",
    "alignment_sequences = [seqrec for seqrec in SeqIO.parse(MSA_filename,\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the starting directory\n",
    "root_dir = \"../raw_sequences\"\n",
    "\n",
    "fasta_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if  \"fasta.fa\" in file.lower():\n",
    "            fasta_path = os.path.join(dirpath, file)\n",
    "            name_path = os.path.join(dirpath, \"name.txt\")\n",
    "            \n",
    "            # check if the name file exists\n",
    "            if os.path.isfile(name_path):\n",
    "                # read the content of the name file\n",
    "                with open(name_path, \"r\") as f:\n",
    "                    name = f.read().strip()\n",
    "            else:\n",
    "                raise Exception(f\"Name file not found {name_path}\")\n",
    "            # append the fasta path and the name to the list as a tuple\n",
    "            fasta_paths.append((fasta_path, name))\n",
    "\n",
    "\n",
    "\n",
    "db_dir = os.path.join(work_dir,\"db_data/\")\n",
    "db_filename = os.path.join(db_dir,\"my_blast_db\")\n",
    "db_sequences_filename = os.path.join(db_dir,\"db_sequences.fa\")\n",
    "\n",
    "if not os.path.exists(db_dir):\n",
    "    os.mkdir(db_dir)\n",
    "else:\n",
    "    !rm -rf $db_dir\n",
    "    os.mkdir(db_dir)\n",
    "\n",
    "db_sequences = []\n",
    "for sequence in alignment_sequences:\n",
    "    seq = sequence.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    db_sequences.append(SeqRecord(seq_without_gaps, id=sequence.id, description=sequence.description))\n",
    "SeqIO.write(db_sequences, db_sequences_filename, \"fasta\")\n",
    "!makeblastdb -in {db_sequences_filename} -dbtype prot -out {db_filename}\n",
    "\n",
    "import subprocess\n",
    "\n",
    "path_accessions = []\n",
    "for i in tqdm(range(0,len(fasta_paths)),desc=\"Loading Accession Codes\"):\n",
    "    fasta_path = fasta_paths[i][0]\n",
    "#     print(f\"{i+1}/{len(fasta_paths)} Processing {fasta_path}\")\n",
    "    shortened_path = fasta_paths[i][1]\n",
    "    output = subprocess.run(f\"blastp -db {db_filename} -query {fasta_path} -outfmt '6 sseqid' -max_target_seqs 1 -evalue 1e-50\", shell=True, capture_output=True)\n",
    "    accession_numbers = output.stdout.decode().strip().split(\"\\n\")\n",
    "#     print(f\"Got results:\\n{accession_numbers}\")\n",
    "    path_accessions.append((shortened_path, accession_numbers))\n",
    "    \n",
    "# print(path_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "YcaO_data = []\n",
    "all_annotations_filename = \"../raw_sequences/interpro_all_YcaO_annotated.json\"\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    YcaO_data = json.load(f)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "# Set the y-limits\n",
    "ax.set_ylim(0, len(helix_data))\n",
    "negative_xlim = -800\n",
    "positive_xlim = 450\n",
    "ax.set_xlim(negative_xlim, len(alignment_sequences[0])+positive_xlim)\n",
    "ax.set_xticks(range(0, len(alignment_sequences[0]), 200))\n",
    "processed_secondary_structure_data = []\n",
    "rect_height = 4/5\n",
    "for i in tqdm(range(0,len(helix_data))):\n",
    "    file = helix_data[i]\n",
    "    accession = file[\"accession\"]\n",
    "    name = \"\"\n",
    "    for path_accession in path_accessions:\n",
    "        if(path_accession[1][0] == accession):\n",
    "            name = path_accession[0]\n",
    "    ax.annotate(name, (negative_xlim, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=6,\n",
    "                                ha='left', va='center')\n",
    "    \n",
    "    for sequence in alignment_sequences:\n",
    "        if(sequence.id == accession):\n",
    "            seq_info = get_item_by_accession(YcaO_data,accession)\n",
    "            domain_start = seq_info[\"YcaO_domain\"][\"start\"]+1\n",
    "            domain_end = seq_info[\"YcaO_domain\"][\"end\"]+1\n",
    "            actual_pos = domain_start\n",
    "            pos_array = []\n",
    "            for char in sequence.seq:\n",
    "                if char != \"-\":\n",
    "                    actual_pos += 1\n",
    "                pos_array.append(actual_pos)\n",
    "            helix_positions = []\n",
    "            start_helix = 0\n",
    "            for helix in file[\"h\"]:\n",
    "                if(helix[1]>domain_start and helix[2]<domain_end):\n",
    "                    helix_length = helix[2]-helix[1]\n",
    "                    MSA_length = pos_array.index(helix[2])-pos_array.index(helix[1])\n",
    "                    stretch_factor = helix_length/MSA_length\n",
    "                    helix_positions.append([helix[0],pos_array.index(helix[1]),pos_array.index(helix[2])])\n",
    "                    x_start, x_end = pos_array.index(helix[1]),pos_array.index(helix[2])\n",
    "                    rect_width = x_end - x_start\n",
    "                    rect_height = 4/5\n",
    "                    rect = plt.Rectangle((x_start, i), rect_width, rect_height, alpha=stretch_factor)\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.annotate(f'{round(stretch_factor,2)}', (x_start+rect_width/2, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=8,\n",
    "                                ha='center', va='center')\n",
    "                    \n",
    "                else:\n",
    "                    start_helix +=1\n",
    "            sheet_positions = []\n",
    "            for sheet in file[\"b\"]:\n",
    "                if(sheet[1]>domain_start and sheet[2]<domain_end):\n",
    "                    sheet_length = sheet[2]-sheet[1]\n",
    "                    MSA_length = pos_array.index(sheet[2])-pos_array.index(sheet[1])\n",
    "                    stretch_factor = sheet_length/MSA_length\n",
    "                    sheet_positions.append([sheet[0],pos_array.index(sheet[1]),pos_array.index(sheet[2])])\n",
    "                    x_start, x_end = pos_array.index(sheet[1]),pos_array.index(sheet[2])\n",
    "                    rect_width = x_end - x_start\n",
    "                    \n",
    "                    rect = plt.Rectangle((x_start, i), rect_width, rect_height, alpha=stretch_factor,color=\"red\")\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.annotate(f'{round(stretch_factor,2)}', (x_start+rect_width/2, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=8,\n",
    "                                ha='center', va='center')\n",
    "            processed_secondary_structure_data.append({\"accession\":accession,\"h\":helix_positions,\"b\":sheet_positions})\n",
    "\n",
    "# Set the x-limits and remove the y-axis ticks and labels\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Alignment of secondary structure elements in MAFFT Multiple Sequence Alignment')\n",
    "ax.set_xlabel('Residue position')\n",
    "ax.set_ylabel('Protein')\n",
    "# Show the plot\n",
    "legend_elements = [    Patch(facecolor='red', alpha=0.5, label='Beta Sheets'),    Patch(facecolor='blue', alpha=0.5, label='Alpha Helices')]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1676c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_data = np.zeros(len(alignment_sequences))\n",
    "for i in tqdm(range(0,len(alignment_sequences)),desc=\"getting occupancy data\"):\n",
    "    sequence = alignment_sequences[i]\n",
    "    for i in range(0,len(sequence.seq)):\n",
    "        char = sequence.seq[i]\n",
    "        if(char != \"-\"):\n",
    "            occupancy_data[i] += 1\n",
    "\n",
    "occupancy_data = occupancy_data/len(alignment_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(negative_xlim, len(alignment_sequences[0])+positive_xlim)\n",
    "ax.set_xticks(range(0, len(alignment_sequences[0]), 200))\n",
    "im = ax.imshow(np.array([occupancy_data, occupancy_data]), cmap='gray_r', aspect='auto', vmin=0, vmax=1)\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Occupancy of each position in MAFFT MSA')\n",
    "ax.set_xlabel('Residue position')\n",
    "plt.colorbar(im, label='% Occupancy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
