{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cc068c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:40px\" align=\"center\"> Load Sequences from Interpro </h1><br><br><br><br><br><br>\n",
    "\n",
    "##### Only run this if you need to tbh, you dont want rewrite the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371bdc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# standard library modules\n",
    "import sys, errno, re, json, ssl\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError\n",
    "from time import sleep\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import requests\n",
    "import xmltodict\n",
    "import concurrent.futures\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810cb6f9-774f-4f3e-8903-1f754f651420",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.ebi.ac.uk:443/interpro/api/protein/UniProt/entry/pfam/PF05935/?page_size=200&extra_fields=sequence&taxonomy\"\n",
    "output_filename = '../data/annotated_sequences.json'\n",
    "installation_progress_filename = \"../data/url_progress.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172b16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/annotated_sequences.json', 'w') as f:\n",
    "    json.dump([],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f33f4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_additional_info(seq_data):\n",
    "    accession = seq_data[\"Accession_Interpro\"]\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}.xml\"\n",
    "    response = requests.get(url)\n",
    "    xml_data = xmltodict.parse(response.text)\n",
    "    if(response.status_code == 200):\n",
    "        seq_data[\"lineage\"] = xml_data['uniprot']['entry']['organism']['lineage'][\"taxon\"]\n",
    "        seq_data[\"Accession_RefSeq\"] = \"\"\n",
    "        seq_data[\"Accession_AlphaFoldDB\"] = \"\"\n",
    "        for reference in xml_data['uniprot']['entry']['dbReference']:\n",
    "            try:\n",
    "                if reference['@type'] == 'RefSeq' or reference['@type'] == 'AlphaFoldDB':\n",
    "                    id = reference['@id']\n",
    "                    seq_data[\"Accession_\"+reference[\"@type\"]] = id\n",
    "            except:\n",
    "                print(f\"\\n Failed to get info for {accession}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"FAILED RETRIEVING ADDITIONAL DATA FOR {accession}\")\n",
    "    return seq_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13525ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Starting to load sequences and identifiers from scratch!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a0g4f9w9&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a0r9pem7&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a177p0b0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a1h2ghv5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a1q6n5n3&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 1000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a1y5mz88&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 1200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2a5daa7&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 1400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2d9qkl9&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 1600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2e4ust5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 1800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2g2hg94&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 2000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2r4hlz4&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 2200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a2t9qb45&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 2400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a316ua41&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 2600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a376qen5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 2800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a3a4k454&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 3000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a3g2h9u2&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 3200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a3r7tsf5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 3400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a3v8r2v2&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 3600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a416dvd1&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 3800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a4p5w194&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 4000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a4v5npl0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 4200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a533tep0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 4400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a5h7d1y1&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 4600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a5j0n8u2&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 4800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a5u0lt33&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 5000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a5w4bfg0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 5200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a5y8dni8&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 5400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a623ee72&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 5600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a659pjw9&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 5800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a6g5r5b7&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 6000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a6m3p3a5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 6200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a6y2xzk0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 6400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a726y563&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 6600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a736he16&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 6800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a748gkr7&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 7000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a7c5r6m0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 7200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a7k2ej42&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 7400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a7t8fg90&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 7600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a7x3kja6&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 7800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a7y7adm1&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 8000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a842qeg1&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 8200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a8e6wzi5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 8400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a917c2p9&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 8600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a936ufc0&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 8800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a947elp9&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 9000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a957dkb7&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 9200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a960e8i5&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 9400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a9d2feg4&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 9600\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Aa0a9e5zel6&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 9800\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Ab6xue8&extra_fields=sequence&page_size=200&taxonomy=\n",
      "\n",
      " Failed to get info for A0A9P0S6Z2\n",
      "\n",
      " Failed to get info for A0A9P0S6Z2\n",
      "\n",
      " Failed to get info for A0A9P0S6Z2\n",
      "\n",
      " Failed to get info for A0A9P0SFN7\n",
      "\n",
      " Failed to get info for A0A9P0SFN7\n",
      "\n",
      " Failed to get info for A0A9P0SFN7\n",
      "\n",
      " Failed to get info for A0A9P3DZB6\n",
      "\n",
      " Failed to get info for A0A9P3DZB6\n",
      "\n",
      " Failed to get info for A0A9P3DZB6\n",
      "\n",
      " Failed to get info for A0A9P2N1E9\n",
      "\n",
      " Failed to get info for A0A9P2N1E9\n",
      "\n",
      " Failed to get info for A0A9P2N1E9\n",
      "\n",
      " Failed to get info for A0A9Q2Q9D5\n",
      "\n",
      " Failed to get info for A0A9Q2Q9D5\n",
      "\n",
      " Failed to get info for A0A9Q2Q9D5\n",
      "\n",
      " Failed to get info for A0A9Q6TFK3\n",
      "\n",
      " Failed to get info for A0A9Q6TFK3\n",
      "\n",
      " Failed to get info for A0A9Q6TFK3\n",
      "\n",
      " Failed to get info for A0A9Q6U0S5\n",
      "\n",
      " Failed to get info for A0A9Q6U0S5\n",
      "\n",
      " Failed to get info for A0A9Q6U0S5\n",
      "\n",
      " Failed to get info for A0A9Q6UCQ5\n",
      "\n",
      " Failed to get info for A0A9Q6UCQ5\n",
      "\n",
      " Failed to get info for A0A9Q6UCQ5\n",
      "Processed 200 in the last batch, total 10000\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Af6dse8&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 10200\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3Am0dfa8&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 10400\n",
      "...Progress Saved!\n",
      "https://www.ebi.ac.uk/interpro/api/protein/UniProt/entry/pfam/PF05935/?cursor=source%3As%3As0fuq1&extra_fields=sequence&page_size=200&taxonomy=\n",
      "Processed 200 in the last batch, total 10600\n",
      "...Progress Saved!\n",
      "None\n",
      "Processed 141 in the last batch, total 10741\n",
      "...Progress Saved!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to load sequences and identifiers from scratch!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 102\u001b[0m total_data \u001b[38;5;241m=\u001b[39m \u001b[43moutput_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 86\u001b[0m, in \u001b[0;36moutput_list\u001b[0;34m(next)\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Progress Saved!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 86\u001b[0m       f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mnext\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_data\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "def output_list(next = BASE_URL):\n",
    "  #disable SSL verification to avoid config issues\n",
    "  context = ssl._create_unverified_context()\n",
    "  last_page = False\n",
    "  total_data = []\n",
    "\n",
    "  if(next != BASE_URL):\n",
    "        print(\"Not starting from the beginning! Loading previous Json!\")\n",
    "        with open(output_filename, 'r') as f:\n",
    "            # load the data from the file\n",
    "            total_data = json.load(f)\n",
    "        print(f\"We have a total of {len(total_data)} sequences!\")\n",
    "        print(\"\\nContinuing where we left off!...\\n\")\n",
    "        \n",
    "  attempts = 0\n",
    "  while next:\n",
    "    try:\n",
    "      req = request.Request(next, headers={\"Accept\": \"application/json\"})\n",
    "      res = request.urlopen(req, context=context)\n",
    "      # If the API times out due a long running query\n",
    "      if res.status == 408:\n",
    "        # wait just over a minute\n",
    "        sleep(61)\n",
    "        # then continue this loop with the same URL\n",
    "        continue\n",
    "      elif res.status == 204:\n",
    "        #no data so leave loop\n",
    "        break\n",
    "      payload = json.loads(res.read().decode())\n",
    "      next = payload[\"next\"]\n",
    "      print(next)\n",
    "      \n",
    "      attempts = 0\n",
    "      if not next:\n",
    "        last_page = True\n",
    "    except HTTPError as e:\n",
    "      if e.code == 408:\n",
    "        sleep(61)\n",
    "        continue\n",
    "      else:\n",
    "        # If there is a different HTTP error, it wil re-try 3 times before failing\n",
    "        if attempts < 3:\n",
    "          attempts += 1\n",
    "          sleep(61)\n",
    "          continue\n",
    "        else:\n",
    "          sys.stderr.write(\"LAST URL: \" + next)\n",
    "          raise e\n",
    "    data = []\n",
    "    for i, item in enumerate(payload[\"results\"]):\n",
    "      entries = None\n",
    "      if (\"entry_subset\" in item):\n",
    "        entries = item[\"entry_subset\"]\n",
    "      elif (\"entries\" in item):\n",
    "        entries = item[\"entries\"]\n",
    "      \n",
    "      seq_data = {}\n",
    "      if entries is not None:\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for entry in entries:\n",
    "          for locations in entry['entry_protein_locations']:\n",
    "            for fragment in locations['fragments']:\n",
    "              start = fragment['start']\n",
    "              end = fragment['end']\n",
    "        \n",
    "        seq_data[\"Accession_Interpro\"] = item[\"metadata\"][\"accession\"]\n",
    "        seq_data[\"domain_boundaries\"] = {\"start\":start, \"end\":end}\n",
    "      seq_data[\"seq\"] = item[\"extra_fields\"][\"sequence\"]\n",
    "      data.append(seq_data)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # submit a task to retrieve information for each accession\n",
    "        tasks = [executor.submit(get_additional_info, seq_data) for seq_data in data]\n",
    "\n",
    "        # retrieve the results of the tasks as they complete\n",
    "        results = [task.result() for task in concurrent.futures.as_completed(tasks)]\n",
    "\n",
    "    \n",
    "    total_data.extend(data)\n",
    "    print(f\"Processed {len(data)} in the last batch, total {len(total_data)}\")\n",
    "    # Don't overload the server, give it time before asking for more\n",
    "    with open(output_filename, 'w') as f:\n",
    "        json.dump(total_data,f)\n",
    "        print(\"...Progress Saved!\")\n",
    "    with open(installation_progress_filename, \"a\") as f:\n",
    "        f.write(\"\\n\"+next)\n",
    "        \n",
    "  return total_data\n",
    "print(\"Hello\")\n",
    "total_data = []\n",
    "url = BASE_URL\n",
    "if os.path.exists(installation_progress_filename):\n",
    "    print(\"Identified pre existing save, loading... \")\n",
    "    with open(installation_progress_filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            url = lines[-1]\n",
    "else:\n",
    "    print(\"Starting to load sequences and identifiers from scratch!\")\n",
    "    open(installation_progress_filename, \"w\").close()\n",
    "    \n",
    "total_data = output_list(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af229188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_data = []\n",
    "\n",
    "with open('../processed_sequences/annotated_sequences.json', 'r') as f:\n",
    "    total_data = json.load(f)\n",
    "#total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0f745-f4c5-4cff-a561-6b10a0702e43",
   "metadata": {},
   "source": [
    "# From the downloaded json, create a trimmed sequences data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff3797-e9df-4542-b706-ebd048b0dab1",
   "metadata": {},
   "source": [
    "# From the downloaded json, create a non trimmed sequences data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8dfc25-c407-47d8-9df1-fbf2a0b3a10f",
   "metadata": {},
   "source": [
    "# Get Sequence information, such as domain architecture from Interpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2492e42b-b5b6-48fe-9dc3-9e36f157dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqIO import write\n",
    "import requests\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "temp_filename = \"del_me_temp_file_loading_domain_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7eaf05c-76c6-4e26-8824-9a00eb073f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = \"../../../data/ASST_raw_sequences/ASSTs_annotated_sequences.json\"\n",
    "output_filename = \"../../../data/ASST_raw_sequences/ASSTs_domain_data.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f980e59a-9834-462a-bca3-ffb31078227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G3DSA:2.130.10.10\n",
      "IPR010262\n",
      "IPR011047\n",
      "IPR015943\n",
      "PF05935\n",
      "PTHR35340\n",
      "SSF50998\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the InterPro API endpoint\n",
    "interpro_api_url = \"https://www.ebi.ac.uk/interpro/api/entry/all/protein/unreviewed/\"\n",
    "# Replace 'your_accession_number' with the actual InterPro accession number\n",
    "accession_number = 'A0A009Y387'\n",
    "\n",
    "# Construct the API request URL\n",
    "request_url = f\"{interpro_api_url}/{accession_number}\"\n",
    "\n",
    "# Send the request\n",
    "response =  requests.get(request_url, timeout=10)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    for result in data[\"results\"]:\n",
    "        print(result[\"metadata\"][\"accession\"])\n",
    "    # Extract domain architecture information\n",
    "    domain_architecture = data.get('entries', {}).get('interpro', {}).get('entry_protein_locations', [])\n",
    "\n",
    "    # Print or process the domain architecture information as needed\n",
    "    print(domain_architecture)\n",
    "else:\n",
    "    # Handle errors\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bb45b-b1d6-475f-b0f0-26341080ee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous save identified, loading previous data\n",
      "Starting from position 5791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  54%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 5834/10741 [13:07:34<59:21,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A661YN05 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  57%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 6071/10741 [13:11:28<1:18:22,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  57%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 6087/10741 [13:11:48<1:23:10,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A6J4GPH2 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  57%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 6171/10741 [13:13:07<57:48,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  58%|███████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 6236/10741 [13:14:14<1:05:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  58%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 6251/10741 [13:14:33<1:11:06,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A6N8VSK0 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  58%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 6254/10741 [13:14:35<53:52,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A6N8Y2X6 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  59%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 6300/10741 [13:15:24<1:13:45,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A6S5K6K0 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 7061/10741 [13:25:11<55:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 7067/10741 [13:25:21<1:12:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 7070/10741 [13:25:30<2:07:43,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 7153/10741 [13:41:19<44:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7A3AAF6 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 7163/10741 [13:41:26<45:04,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7C1TC87 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 7171/10741 [13:41:35<1:00:41,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 7248/10741 [13:43:03<1:11:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7C7X575 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 7249/10741 [13:43:03<57:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7C7X8V5 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 7280/10741 [13:43:38<53:26,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7D6P8Z4 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 7294/10741 [13:43:50<48:54,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7G3F2X5 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 7324/10741 [13:44:22<1:03:47,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7I7ADA8 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 7663/10741 [13:50:04<56:58,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out, retrying (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7677/10741 [13:50:27<1:07:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7V8TJM8 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 7747/10741 [13:51:35<48:58,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7W3EVF0 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 7750/10741 [13:51:38<41:54,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7W3ICF2 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 7839/10741 [13:53:10<53:35,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7X6E910 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 7863/10741 [13:53:35<54:49,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7X8P6G5 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 7884/10741 [13:53:56<36:52,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Y1YPQ6 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 7925/10741 [13:54:32<46:24,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Y2UG65 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 7926/10741 [13:54:32<37:50,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Y2UGQ7 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 7927/10741 [13:54:33<32:47,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Y2UKQ2 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 7996/10741 [13:55:48<50:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Y7A8L5 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 8025/10741 [13:56:20<59:39,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A7Z2K9Y6 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 8065/10741 [13:57:02<39:11,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A800BEB1 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 8091/10741 [13:57:26<39:29,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A822LWH9 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 8095/10741 [13:57:30<51:39,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A826QRQ1 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 8099/10741 [13:57:34<50:26,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A827KSV4 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 8103/10741 [13:57:38<44:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A828GJN7 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 8111/10741 [13:57:46<44:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A829IX78 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 8123/10741 [13:57:57<39:08,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A831JCI5 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 8150/10741 [13:58:28<46:49,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A837DPC3 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 8236/10741 [14:01:07<37:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A844JQQ1 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 8244/10741 [14:01:14<36:16,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A846FBI8 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 8274/10741 [14:01:42<38:52,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A848J616 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 8304/10741 [14:02:11<46:30,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Missing data for - A0A855N1C7 - Continuing regardless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Domain information:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 8307/10741 [14:02:13<35:22,  1.15it/s]"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "def get_domain_info(accession_number, element):\n",
    "    max_retries = 3\n",
    "\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            # Construct the API request URL\n",
    "            request_url = f\"https://www.ebi.ac.uk/interpro/api/entry/all/protein/unreviewed/{accession_number}?format=json\"\n",
    "\n",
    "            # Send the request with a timeout\n",
    "            response = requests.get(request_url, timeout=3)\n",
    "\n",
    "            # Check if the request was successful (status code 200)\n",
    "            if response.status_code == 200:\n",
    "                # Parse the JSON response\n",
    "                data = response.json()\n",
    "\n",
    "                domain_info = []\n",
    "\n",
    "                for result in data[\"results\"]:\n",
    "                    accession = \"\"\n",
    "                    if not result[\"metadata\"][\"accession\"]:\n",
    "                        continue\n",
    "\n",
    "                    accession = result[\"metadata\"][\"accession\"]\n",
    "                    for key, value in result[\"metadata\"].items():\n",
    "                        if not isinstance(value, str):\n",
    "                            continue\n",
    "                        if value.startswith('IPR'):\n",
    "                            accession = value\n",
    "\n",
    "                    if accession not in domain_info:\n",
    "                        domain_info.append(accession)\n",
    "\n",
    "                return domain_info\n",
    "            elif response.status_code == 204:\n",
    "                print(f\"Error: Missing data for - {accession_number} - Continuing regardless\")\n",
    "                return [\"error\"]\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text} - {accession_number} - {element}\")\n",
    "                raise Exception(\"Request went wrong, please restart this script\")\n",
    "\n",
    "        except Timeout:\n",
    "            if retry < max_retries - 1:\n",
    "                print(f\"Request timed out, retrying ({retry + 1}/{max_retries})...\")\n",
    "            else:\n",
    "                print(f\"Request timed out after {max_retries} retries, raising exception.\")\n",
    "                raise Exception(\"Request timed out after multiple retries\")\n",
    "    \n",
    "\n",
    "\n",
    "data = []\n",
    "with open(data_filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "all_domain_info = []\n",
    "index = 0\n",
    "if not os.path.exists(temp_filename):\n",
    "    # If it doesn't exist, create the file\n",
    "    print(\"No previous temp file found, starting from scratch!\")\n",
    "    with open(temp_filename, 'w') as temp:\n",
    "        json.dump({\"index\":index}, temp, indent=4)\n",
    "    \n",
    "else:\n",
    "    print(\"Previous save identified, loading previous data\")\n",
    "    with open(temp_filename, 'r') as file:\n",
    "        index = json.load(file)[\"index\"]\n",
    "        print(f\"Starting from position {index}\")\n",
    "    with open(output_filename, 'r') as file:\n",
    "        all_domain_info = json.load(file)\n",
    "\n",
    "for i in tqdm(range(0,len(data)), desc=\"Loading Domain information\"):\n",
    "    if(i < index):\n",
    "        continue\n",
    "    element = data[i]\n",
    "    accession_interpro = element[\"Accession_Interpro\"]\n",
    "\n",
    "    domains = get_domain_info(accession_interpro,element)\n",
    "    all_domain_info.append({\"Accession_Interpro\":accession_interpro, \"domains\":domains})\n",
    "    with open(output_filename, 'w') as outfile:\n",
    "        json.dump(all_domain_info, outfile, indent=4)\n",
    "    index += 1\n",
    "    with open(temp_filename, 'w') as temp:\n",
    "        json.dump({\"index\":index}, temp, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6be1b7",
   "metadata": {},
   "source": [
    "# Since the sequences have already been loaded, no need to run the previous script, just use the stuff below to reload the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = []\n",
    "\n",
    "with open('../raw_sequences/annotated_sequences.json', 'r') as f:\n",
    "    total_data = json.load(f)\n",
    "#total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_list(data, result={}):\n",
    "    for item in data:\n",
    "        lineage = item[\"lineage\"]\n",
    "        if lineage:\n",
    "            lineage_dict = result\n",
    "            for level in lineage:\n",
    "                if level not in lineage_dict:\n",
    "                    lineage_dict[level] = {}\n",
    "                lineage_dict = lineage_dict[level]\n",
    "            lineage_dict.update(item)\n",
    "    return result\n",
    "\n",
    "transformed_data = transform_list(total_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3df89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(data, family):\n",
    "    return [s for s in data if family in s['lineage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Draw_Pie(data, depth = 2):\n",
    "    # Create a defaultdict to store the count of each lineage\n",
    "    lineage_count = defaultdict(int)\n",
    "\n",
    "    # Iterate through the list of dictionaries and count the occurrences of each lineage\n",
    "    for item in data:\n",
    "        try:\n",
    "            lineage_count[item[\"lineage\"][depth]] += 1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # Extract the labels (lineage names) and sizes (counts) for the pie chart\n",
    "    labels = list(lineage_count.keys())\n",
    "    sizes = list(lineage_count.values())\n",
    "\n",
    "    # Create the pie chart\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')  # Ensure the chart is a circle, not an ellipse\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803fd7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Draw_Pie(total_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio as bio\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "\n",
    "family = \"Cyanobacteria\"\n",
    "filterByDomain = True\n",
    "\n",
    "sequences = get_sequences(total_data,family)\n",
    "seq_recs = []\n",
    "for seq_data in sequences:\n",
    "    seq = Seq(seq_data[\"seq\"])\n",
    "    if(filterByDomain):\n",
    "        seq = seq[seq_data[\"YcaO_domain\"][\"start\"]:seq_data[\"YcaO_domain\"][\"end\"]]\n",
    "    seq_recs.append(SeqRecord(seq, id=seq_data[\"Accession_Interpro\"]))\n",
    "\n",
    "dirname = f'../processed_sequences/{family}_sequences'\n",
    "filename = f\"{family}_{'YcaO_only' if filterByDomain else 'whole_protein'}.fa\"\n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    # Create the directory\n",
    "    os.makedirs(dirname)\n",
    "    \n",
    "SeqIO.write(seq_recs,os.path.join(dirname,filename), \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a666932-5bf3-4d7d-9028-985f36dbc985",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Get Sequences for Rodeo </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13688d62-c215-4e83-9694-4e4df319b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "def get_item_by_RefSeq_accession(seqs, accession):\n",
    "    print(accession)\n",
    "    for item in seqs:\n",
    "        if('Accession_RefSeq' in item):\n",
    "            if item['Accession_RefSeq'] == accession.split(\".\")[0]:\n",
    "                return item\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6db0e-8827-48ae-8ed9-ceb90230a4fc",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83ae0ba-d96d-40a8-bf05-47bc37242234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to work on all the sequences within the json, leave this variable empty\n",
    "input_sequences_filename = \"\" \n",
    "\n",
    "all_annotations_filename = \"../../../data/ASST_raw_sequences/ASSTs_annotated_sequences.json\"\n",
    "output_folder = \"../../../data/ASST_processed_sequences/RODEO_accessions/\"\n",
    "\n",
    "sequences_per_file = 1000   #Default is 1000, as that is the upper limit of what RODEO will accept, maybe this changes in the future\n",
    "                            #and will need tweeking, but leave it be until then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191a1413-3130-4ee3-9651-51a570fc8185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No input sequences where supplied, hence we are preparing the whole dataset for RODEO analysis\n",
      "10741 sequences have been supplied for RODEO analysis, checking how many have REFSEQ accession numbers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08d42e2c28b45338ac00b9ee31a8021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Identifying sequences with RefSeq Accession:   0%|          | 0/10741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5f906ea18d4cd6bbb5a7cee4ee3e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving sequences to files:   0%|          | 0/1311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311 sequence_IDs have been saved in 2 files.\n",
      "Sequences with RefSeq: 1311, Sequences without RefSeq: 9430\n"
     ]
    }
   ],
   "source": [
    "annotation_data = []\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    annotation_data = json.load(f)\n",
    "\n",
    "sequences = []\n",
    "if (not input_sequences_filename):\n",
    "    print(\"No input sequences where supplied, hence we are preparing the whole dataset for RODEO analysis\")\n",
    "    sequences = [d[\"Accession_Interpro\"] for d in annotation_data]\n",
    "else:\n",
    "    sequences = [seq.id for seq in SeqIO.parse(input_sequences_filename,\"fasta\")]\n",
    "print(f\"{len(sequences)} sequences have been supplied for RODEO analysis, checking how many have REFSEQ accession numbers\")\n",
    "    \n",
    "if not os.path.exists(output_folder):\n",
    "    # If it doesn't exist, create it\n",
    "    print(f\"RODEO output folder '{output_folder}'not found, generating it\")\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "# List to hold the accession RefSeqs\n",
    "refseq_list = []\n",
    "\n",
    "# Counters for sequences with and without RefSeq\n",
    "count_with_refseq = 0\n",
    "count_without_refseq = 0\n",
    "\n",
    "# Process each sequence in the array\n",
    "for seq in tqdm(sequences, desc=\"Identifying sequences with RefSeq Accession\"):\n",
    "    sequence_info = get_item_by_accession(annotation_data,seq)\n",
    "    # Check if 'Accession_RefSeq' is present and not empty\n",
    "    if 'Accession_RefSeq' in sequence_info and sequence_info['Accession_RefSeq']:\n",
    "        refseq_list.append(sequence_info['Accession_RefSeq'])\n",
    "        count_with_refseq += 1\n",
    "    else:\n",
    "        count_without_refseq += 1\n",
    "\n",
    "# Save the RefSeqs to a file\n",
    "file_counter = 1\n",
    "refseqs_saved = 0\n",
    "current_file = None\n",
    "\n",
    "# Iterate through the list of words\n",
    "for refseq in tqdm(refseq_list, desc=\"Saving sequences to files\"):\n",
    "    # Check if it's time to start a new file\n",
    "    if refseqs_saved % sequences_per_file == 0:\n",
    "        if current_file:\n",
    "            current_file.close()\n",
    "        file_name = f\"{output_folder}/RODEO_{file_counter}.txt\"\n",
    "        current_file = open(file_name, \"w\")\n",
    "        file_counter += 1\n",
    "    \n",
    "    # Write the word to the current file\n",
    "    current_file.write(refseq + \"\\n\")\n",
    "    refseqs_saved += 1\n",
    "\n",
    "# Close the last open file\n",
    "if current_file:\n",
    "    current_file.close()\n",
    "\n",
    "print(f\"{refseqs_saved} sequence_IDs have been saved in {file_counter - 1} files.\")\n",
    "\n",
    "print(f\"Sequences with RefSeq: {count_with_refseq}, Sequences without RefSeq: {count_without_refseq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdeab8-f12a-4a17-8d90-69fff0e20781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
